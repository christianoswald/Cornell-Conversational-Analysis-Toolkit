{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiConv Create Conversations\n",
    "\n",
    "This notebook provides different forms of conversations from  the Wikiconv data set. In particular, it showcases the final version of selected conversations and how that conversation developed over time. It also provides a framework to print out rnadomly selected final conversations and the corresponding wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant modules\n",
    "from datetime import datetime, timedelta\n",
    "from convokit import Corpus, User, Utterance, Conversation\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Corpus path  is where the corpus data is stored\n",
    "corpus_path = \"/Users/adityajha/Desktop/Cornell-Conversational-Analysis-Toolkit-master/second_set/conversation_corpus_year_2015\"\n",
    "wikiconv_corpus = Corpus(filename=corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic facts about this subset of the corpus: 10,824 conversations and 22,007 utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10824"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wikiconv_corpus.iter_conversations()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22007"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wikiconv_corpus.iter_utterances()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the corpus, we will randomly select conversations to print out based on a few metrics:\n",
    "1. number_of_conversations - how many conversations we want to print out\n",
    "2. conversation_min_length -  the minimum number of utterances we want in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly chooses the set number of conversations to print from the entire conversaton set\n",
    "def print_random_conversations(conversation_list, number_of_conversations, conversation_min_length,  conversation_corpus): \n",
    "    randomly_generated_conversation_list = []\n",
    "    while (len(randomly_generated_conversation_list) != number_of_conversations):\n",
    "        new_conversation = random.randint(0, (len(conversation_list)-1))\n",
    "        new_conversation_id = conversation_list[new_conversation]\n",
    "        conversation_ids_list = new_conversation_id.get_utterance_ids()\n",
    "        if (new_conversation not in randomly_generated_conversation_list \n",
    "            and (len(conversation_ids_list) >= conversation_min_length)):\n",
    "            randomly_generated_conversation_list.append(new_conversation_id)\n",
    "        \n",
    "    return randomly_generated_conversation_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll get a set of random conversatinos from the corpus based on our specifications (print out 3, conversations, with a minimum length of 2) and the output will be a set of serialized conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<convokit.model.Conversation object at 0x145baca20>, <convokit.model.Conversation object at 0x145e19550>, <convokit.model.Conversation object at 0x145d0a5c0>]\n"
     ]
    }
   ],
   "source": [
    "conversation_list = list(wikiconv_corpus.iter_conversations())\n",
    "number_of_conversations_to_print = 3\n",
    "conversation_min_length = 2\n",
    "\n",
    "random_conversations = print_random_conversations(conversation_list, number_of_conversations_to_print,\n",
    "                                                     conversation_min_length, wikiconv_corpus)\n",
    "print (random_conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, stored in the conversation meta data is the wikipedia information from the page that this conversation is from.\n",
    "We will find that information and print out the link to the associated wikipedia page for each conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=user_talk:50.200.211.205\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:184.185.133.122\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:Starke~enwiki\n"
     ]
    }
   ],
   "source": [
    "def wikipedia_link_info(conversation):\n",
    "    page_title = conversation.meta['page_title']\n",
    "    page_title = re.sub('\\s+', '_', page_title)\n",
    "    page_type = conversation.meta['page_type']\n",
    "    link_value = \"https://en.wikipedia.org/w/index.php?title=\"+page_type+\":\"+page_title\n",
    "    \n",
    "    return link_value\n",
    "\n",
    "for conversation in random_conversations:\n",
    "    print(wikipedia_link_info(conversation))\n",
    "    conversation_ids_list = conversation.get_utterance_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the conversation and the actual wikipedia page where they exist, we will want to print out the conversation's final form from the utterance data. But to do this, first we will need to compute the correct order of the comments. \n",
    "\n",
    "The corpus functionality does not guarantee the comments are in the right order, so we will compute this flow now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For any comments that do not have matching reply to ids, sort these comments in order of recency \n",
    "def sort_by_timestamp(conversation_ids_list, conversation_corpus):\n",
    "    list_of_utterances = []\n",
    "    for id_val in conversation_ids_list:\n",
    "        utterance_value = conversation_corpus.get_utterance(id_val)\n",
    "        timestamp_val = utterance_value.timestamp\n",
    "        tuple_val = (id_val, timestamp_val)\n",
    "        list_of_utterances.append(tuple_val)\n",
    "\n",
    "    sorted_utterance_list = sorted(list_of_utterances, key = lambda x:x[1])\n",
    "    sorted_utterance_list.reverse()\n",
    "    id_list = [i[0] for i in sorted_utterance_list]\n",
    "    return (id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find cases in which an utterance's reply to is to a comment in the chain that has been modified, deleted or restored\n",
    "def check_lists_for_match(x, conversation_ids_list, utterance, next_utterance_value, conversation_corpus):\n",
    "    modification_list = utterance.meta['modification']\n",
    "    deletion_list = utterance.meta['deletion']\n",
    "    restoration_list = utterance.meta['restoration']\n",
    "    if (len(modification_list)>0):\n",
    "        for utterance_val in modification_list:\n",
    "            if (utterance_val.id == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)\n",
    "    if (len(deletion_list)>0):\n",
    "        for utterance_val in deletion_list:\n",
    "            if (utterance_val.id == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)\n",
    "    if (len(restoration_list)>0):\n",
    "        for utterance_val in restoration_list:\n",
    "            if (utterance_val.id == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the conversation flow correctly and add utterances if the reply-to id matches the current utterance in the list\n",
    "def add_utterance(conversation_ids_list, next_utterance_value, conversation_corpus):\n",
    "    if next_utterance_value.id in conversation_ids_list:\n",
    "        return conversation_ids_list\n",
    "    elif (next_utterance_value.reply_to is None):\n",
    "        conversation_ids_list.append(next_utterance_value.id)\n",
    "    else:\n",
    "        for x in range(0,len(conversation_ids_list)):\n",
    "            utterance_id = conversation_ids_list[x]\n",
    "            if (utterance_id == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)\n",
    "            else:\n",
    "                check_lists_for_match(x, conversation_ids_list, conversation_corpus.get_utterance(utterance_id), next_utterance_value, conversation_corpus)\n",
    "\n",
    "    return conversation_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The order of the returned conversation ids is not guaranteed; compute the correct ordering \n",
    "def find_correct_order(conversation_ids_list, conversation_corpus):\n",
    "    correct_list_order = []\n",
    "    #if the conversation has only one comment, return the conversation list\n",
    "    if (len(conversation_ids_list) == 1 ):\n",
    "        return conversation_ids_list\n",
    "\n",
    "    #When the conversation has more than one comment, find the correct order of the comments\n",
    "    if (len(conversation_ids_list) >1):\n",
    "        #Implement a fail safe to efficiently sort \n",
    "        number_of_iterations = 0\n",
    "        while (number_of_iterations <20 and len(correct_list_order) != len(conversation_ids_list)):\n",
    "            for utterance_id in conversation_ids_list:\n",
    "                correct_list_order = add_utterance(correct_list_order, conversation_corpus.get_utterance(utterance_id), conversation_corpus)\n",
    "            number_of_iterations+=1\n",
    "\n",
    "        #In some of the conversations, new utterances will be added that don't reply directly to the current conversation\n",
    "        #Instead, these new utterances are part of the topic at hand (under the same conversation root) and are sorted by recency\n",
    "        if (len(correct_list_order) != len(conversation_ids_list)):\n",
    "            difference_in_sets = set(conversation_ids_list).difference(correct_list_order)\n",
    "            timestamp_sorted_difference = sort_by_timestamp(list(difference_in_sets), conversation_corpus)\n",
    "            correct_list_order.extend(timestamp_sorted_difference)\n",
    "    return correct_list_order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, we can compute the correct order of utterances in each randomly selected conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Order of IDs:['693119069.2.10986', '688099454.12316.12316', '693119069.2.10967', '693119069.2.11819']\n",
      "Correct Order of IDs:['693119069.2.10986', '693119069.2.10967', '693119069.2.11819', '688099454.12316.12316']\n",
      "\n",
      "\n",
      "Original Order of IDs:['693119688.20.0', '693156840.1278.1278', '693119688.0.0']\n",
      "Correct Order of IDs:['693119688.0.0', '693156840.1278.1278', '693119688.20.0']\n",
      "\n",
      "\n",
      "Original Order of IDs:['652619734.0.0', '652619734.35.0']\n",
      "Correct Order of IDs:['652619734.0.0', '652619734.35.0']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for conversation in random_conversations:\n",
    "    conversation_ids_list = conversation.get_utterance_ids()\n",
    "    print ('Original Order of IDs:' + str(conversation_ids_list))\n",
    "    print('Correct Order of IDs:' + str(find_correct_order(conversation_ids_list, wikiconv_corpus)))\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the final form of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the conversation text from the list of conversation ids\n",
    "def print_final_conversation(random_conversations, conversation_corpus):\n",
    "    for conversation in random_conversations:\n",
    "        print(wikipedia_link_info(conversation))\n",
    "        conversation_ids_list = conversation.get_utterance_ids()\n",
    "        #First correctly reorder the comments\n",
    "        ordered_list = find_correct_order(conversation_ids_list, conversation_corpus)\n",
    "        #For each utterance, print the text present if the utterance has not been deleted\n",
    "        for utterance_id in ordered_list:\n",
    "            utterance_value = conversation_corpus.get_utterance(utterance_id)\n",
    "            if (utterance_value.text != \" \"):\n",
    "                print (utterance_value.text)\n",
    "                date_time_val = datetime.fromtimestamp(utterance_value.timestamp).strftime('%H:%M %d-%m-%Y')\n",
    "                formatted_user_name = \"--\" + str(utterance_value.user.name) + \"  \" + str(date_time_val)\n",
    "                print (formatted_user_name)\n",
    "        print ('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=user_talk:50.200.211.205\n",
      " Please refrain from making unconstructive edits to Wikipedia, as you did at North Stafford High School. Your edits appear to constitute vandalism and have been reverted or removed. If you would like to experiment, please use the sandbox. Repeated vandalism can result in the loss of editing privileges. Thank you. ''►  ''' & ''' ◄''\n",
      "''If this is a shared IP address, and you did not make the edits, consider creating an account for yourself so you can avoid further irrelevant notices.''\n",
      "--Bgpaulus  13:03 29-10-2015\n",
      "\n",
      "\n",
      "\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:184.185.133.122\n",
      " November 2015 \n",
      "--ClueBot NG  10:21 30-11-2015\n",
      " Please refrain from making unconstructive edits to Wikipedia, as you did at Arranged marriage in the Indian subcontinent. Your edits continue to appear to constitute vandalism and have been '''automatically''' reverted.\n",
      " If you would like to experiment, please use the sandbox. Note that human editors do monitor recent changes to Wikipedia articles, and administrators have the ability to block users from editing if they repeatedly engage in vandalism.\n",
      " ClueBot NG makes very few , but it does happen. If you believe the change you made should not have been considered as unconstructive, please , [ report it here], remove this warning from your talk page, and then make the edit again.\n",
      "'''If you need help''', please see our '''help pages''', and if you can't find what you are looking for there, please feel free to place  on your talk page and someone will drop by to help.\n",
      " The following is the log entry regarding this warning: Arranged marriage in the Indian subcontinent was changed by    ANN scored at 0.961926 on 2015-11-30T20:10:10+00:00 .\n",
      "Thank you.   \n",
      "--ClueBot NG  15:10 30-11-2015\n",
      " Hello, and welcome to Wikipedia. This is a message letting you know that one or more of your recent edits to Christmas traditions has been undone by an automated computer program called .\n",
      "\n",
      " ClueBot NG makes very few , but it does happen. If you believe the change you made was constructive, please , [ report it here], remove this message from your talk page, and then make the edit again.\n",
      " For help, take a look at the introduction.\n",
      " The following is the log entry regarding this message: Christmas traditions was changed by    ANN scored at 0.955457 on 2015-11-30T15:21:45+00:00 .\n",
      "Thank you.   \n",
      "--ClueBot NG  10:21 30-11-2015\n",
      "\n",
      "\n",
      "\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:Starke~enwiki\n",
      " Your account will be renamed \n",
      "--MediaWiki message delivery  23:10 19-03-2015\n",
      "Hello,\n",
      "The developer team at Wikimedia is making some changes to how accounts work, as part of our on-going efforts to provide new and better tools for our users like cross-wiki notifications. These changes will mean you have the same account name everywhere. This will let us give you new features that will help you edit and discuss better, and allow more flexible user permissions for tools. One of the side-effects of this is that user accounts will now have to be unique across all 900 Wikimedia wikis. See the announcement for more information.\n",
      "Unfortunately, your account clashes with another account also called Starke. To make sure that both of you can use all Wikimedia projects in future, we have reserved the name Starke~enwiki that only you will have. If you like it, you don't have to do anything. If you do not like it, you can pick out a different name. If you think you might own all of the accounts with this name and this message is in error, please visit Special:MergeAccount to check and attach all of your accounts to prevent them from being renamed.\n",
      "Your account will still work as before, and you will be credited for all your edits made so far, but you will have to use the new account name when you log in.\n",
      "Sorry for the inconvenience.\n",
      "Yours,Keegan PeterzellCommunity Liaison, Wikimedia Foundation\n",
      "--MediaWiki message delivery  23:10 19-03-2015\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_final_conversation(random_conversations,  wikiconv_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a compact method to change the default values easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_defaults_print_final(conversation_list, number_of_conversations, conversation_min_length,  \n",
    "                                conversation_corpus):\n",
    "    random_conversations = print_random_conversations(conversation_list, number_of_conversations_to_print,\n",
    "                                                     conversation_min_length, wikiconv_corpus)\n",
    "    print_final_conversation(random_conversations, conversation_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=user_talk:GiantSnowman\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_list = list(wikiconv_corpus.iter_conversations())\n",
    "number_of_conversations_to_print = 1\n",
    "conversation_min_length = 2\n",
    "#Refresher on where the wikiconv_corpus  is defined\n",
    "# corpus_path = \"/Users/adityajha/Desktop/Cornell-Conversational-Analysis-Toolkit-master/second_set/conversation_corpus_year_2015\"\n",
    "# wikiconv_corpus = Corpus(filename=corpus_path)\n",
    "\n",
    "change_defaults_print_final(conversation_list, number_of_conversations_to_print, conversation_min_length,\n",
    "                            wikiconv_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a method to print out the final comment and the intermediate steps in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_changes_by_timestamp(modification_list, deletion_list, restoration_list,  original_utterance):\n",
    "    text_time_tuple_list = []\n",
    "    if (original_utterance is not None):\n",
    "        text_time_original  = (original_utterance.text,original_utterance.timestamp,\n",
    "                           original_utterance.user.name, 'original')\n",
    "        text_time_tuple_list.append(text_time_original)\n",
    "        \n",
    "\n",
    "    for utterance in modification_list:\n",
    "        text_time= (utterance.text, utterance.timestamp,\n",
    "                    utterance.user.name, 'modification')\n",
    "        text_time_tuple_list.append(text_time)\n",
    "    \n",
    "    for utterance in deletion_list:\n",
    "        text_time= ('', utterance.timestamp,\n",
    "                    utterance.user.name, 'deletion')\n",
    "        text_time_tuple_list.append(text_time)\n",
    "        \n",
    "    for utterance in restoration_list:\n",
    "        text_time= (utterance.text, utterance.timestamp,\n",
    "                    utterance.user.name, 'restoration')\n",
    "        text_time_tuple_list.append(text_time)\n",
    "            \n",
    "    text_time_tuple_list.sort(key=lambda x: x[1])\n",
    "    #text_time_tuple_list.reverse()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return text_time_tuple_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_intermediate_conversation(random_conversations, conversation_corpus):\n",
    "    for conversation in random_conversations:\n",
    "        conversation_ids_list = conversation.get_utterance_ids()\n",
    "        #First correctly reorder the comments\n",
    "        ordered_list = find_correct_order(conversation_ids_list, conversation_corpus)\n",
    "        #For each utterance, print the text present if the utterance has not been deleted\n",
    "        for utterance_id in ordered_list:\n",
    "            utterance_value = conversation_corpus.get_utterance(utterance_id)\n",
    "            if (utterance_value.text != \" \"):\n",
    "                final_comment =  utterance_value.text\n",
    "                date_time_val = datetime.fromtimestamp(utterance_value.timestamp).strftime('%H:%M %d-%m-%Y')\n",
    "                formatted_user_name = \"--\" + str(utterance_value.user.name) + \"  \" + str(date_time_val)\n",
    "                \n",
    "        \n",
    "                final_timestamp = utterance_value.timestamp\n",
    "                modification_list = utterance_value.meta['modification']\n",
    "                deletion_list = utterance_value.meta['deletion']\n",
    "                restoration_list = utterance_value.meta['restoration']\n",
    "                \n",
    "                sorted_timestamps = sort_changes_by_timestamp(modification_list, deletion_list, restoration_list,\n",
    "                                                             utterance_value.meta['original'])\n",
    "                \n",
    "                if (len(sorted_timestamps)>0):\n",
    "                    print(wikipedia_link_info(conversation))\n",
    "                    print ('Final Comment')\n",
    "                    print (final_comment)\n",
    "                    print (formatted_user_name)\n",
    "                    \n",
    "                    for value in sorted_timestamps:\n",
    "                        print ('\\n')\n",
    "                        print (value[3])\n",
    "                        print (value[0])\n",
    "                        formatted_user_name = \"--\" + str(value[2]) + \"  \" + str(datetime.fromtimestamp(float(value[1])).strftime('%H:%M %d-%m-%Y'))\n",
    "                        #str(datetime.fromtimestamp(value[1]).strftime('%H:%M %d-%m-%Y'))\n",
    "                        print (formatted_user_name)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method to quikcly print out intermediate conversations defined below (only conversations with modification, deletion and restoration conversations  are shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_defaults_print_intermediate(conversation_list, number_of_conversations, conversation_min_length,  \n",
    "                                conversation_corpus):\n",
    "    random_conversations = print_random_conversations(conversation_list, number_of_conversations_to_print,\n",
    "                                                     conversation_min_length, wikiconv_corpus)\n",
    "    print_intermediate_conversation(random_conversations, conversation_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the flow of different conversations  is shown with the final comment first displayed and the corresponding actions that have occurred from earliest to latest actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=user_talk:197.34.120.203\n",
      "Final Comment\n",
      " Please stop adding inappropriate external links to Wikipedia. It is considered spamming and Wikipedia is not a vehicle for advertising or promotion. Because Wikipedia uses nofollow tags, additions of links to Wikipedia will not alter search engine rankings. If you continue spamming, you may be blocked from editing Wikipedia.   ''''  \n",
      "--Deli nk  12:05 03-05-2015\n",
      "\n",
      "\n",
      "original\n",
      " Please stop your disruptive editing. If you continue to vandalize Wikipedia, you may be blocked from editing. ''SPAM: ''  \n",
      "''If this is a shared IP address, and you did not make the edits, consider creating an account for yourself so you can avoid further irrelevant notices.''\n",
      "--Deli nk  12:04 03-05-2015\n",
      "\n",
      "\n",
      "modification\n",
      " Please stop adding inappropriate external links to Wikipedia. It is considered spamming and Wikipedia is not a vehicle for advertising or promotion. Because Wikipedia uses nofollow tags, additions of links to Wikipedia will not alter search engine rankings. If you continue spamming, you may be blocked from editing Wikipedia.   ''''  \n",
      "--Deli nk  12:05 03-05-2015\n",
      "https://en.wikipedia.org/w/index.php?title=talk:Acetylene\n",
      "Final Comment\n",
      "alternatively: acidify ethylene glycol, acetethylene(glycol)> acet(h)ylene  (ethylene glycol > -H2O > ethylene oxide/epoxide> -H2O > acetylene; epoxide may polymerize, but sulfuric acid can dehydrate the epoxide, I guess) \n",
      "--CCR4711  23:08 10-04-2015\n",
      "\n",
      "\n",
      "original\n",
      "alternatively: acidify ethylene glycol, acetethylene(glycol)> acethylene, (also: ethylene-1,2-diol/dihalogenide) \n",
      "--CCR4711  22:56 10-04-2015\n",
      "\n",
      "\n",
      "modification\n",
      "alternatively: acidify ethylene glycol, acetethylene(glycol)> acethylene  (epoxide may polymerize, but sulfuric acid can dehydrate the epoxide, I guess) \n",
      "--CCR4711  23:04 10-04-2015\n",
      "\n",
      "\n",
      "modification\n",
      "alternatively: acidify ethylene glycol, acetethylene(glycol)> acethylene  (ethylene glycol > -H2O > ethylene oxide/epoxide> -H2O > acetylene; epoxide may polymerize, but sulfuric acid can dehydrate the epoxide, I guess) \n",
      "--CCR4711  23:07 10-04-2015\n",
      "\n",
      "\n",
      "modification\n",
      "alternatively: acidify ethylene glycol, acetethylene(glycol)> acet(h)ylene  (ethylene glycol > -H2O > ethylene oxide/epoxide> -H2O > acetylene; epoxide may polymerize, but sulfuric acid can dehydrate the epoxide, I guess) \n",
      "--CCR4711  23:08 10-04-2015\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:GiantSnowman\n",
      "Final Comment\n",
      " Greek IP \n",
      "--84.90.219.128  11:26 08-09-2015\n",
      "\n",
      "\n",
      "original\n",
      " Greek IP \n",
      "--84.90.219.128  09:48 14-08-2015\n",
      "\n",
      "\n",
      "deletion\n",
      "\n",
      "--GiantSnowman  12:32 14-08-2015\n",
      "\n",
      "\n",
      "restoration\n",
      " Greek IP \n",
      "--84.90.219.128  11:26 08-09-2015\n",
      "https://en.wikipedia.org/w/index.php?title=talk:Apeirogon\n",
      "Final Comment\n",
      "Thanks , think we have to wait till it is published, not sure about it all: What is an pseudogon? , the illustration doesn't show a lot (only when you look at the original file you see the  pseudogon boundary, a thin red line)  but even then is it just the red segmented arc, is it the area above this arc,is it the area below it, or are both half planes pseudogons?  \n",
      "--WillemienH  17:09 13-08-2015\n",
      "\n",
      "\n",
      "original\n",
      "Thanks , think we have to wait till it is published, not sure about it all: What is an pseudogon? , the illustration doesn't look correct (only when you look at the original file you see the  pseudogon boundary, the thin red line)  but even then is it just the red segmented arc or the area above or the area below it? \n",
      "--WillemienH  10:43 12-08-2015\n",
      "\n",
      "\n",
      "modification\n",
      "Thanks , think we have to wait till it is published, not sure about it all: What is an pseudogon? , the illustration doesn't show a lot (only when you look at the original file you see the  pseudogon boundary, a thin red line)  but even then is it just the red segmented arc, is it the area above this arc,is it the area below it, or are both half planes pseudogons?  \n",
      "--WillemienH  17:09 13-08-2015\n"
     ]
    }
   ],
   "source": [
    "conversation_list = list(wikiconv_corpus.iter_conversations())\n",
    "number_of_conversations_to_print = 10\n",
    "conversation_min_length = 3\n",
    "#Refresher on where the wikiconv_corpus  is defined\n",
    "# corpus_path = \"/Users/adityajha/Desktop/Cornell-Conversational-Analysis-Toolkit-master/second_set/conversation_corpus_year_2015\"\n",
    "# wikiconv_corpus = Corpus(filename=corpus_path)\n",
    "\n",
    "change_defaults_print_intermediate(conversation_list, number_of_conversations_to_print, conversation_min_length,\n",
    "                            wikiconv_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
