{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the orientation of phrases and utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demos an unsupervised procedure for deriving the _orientation_ of a phrase in an utterance, a measure of the extent to which it aims forwards in a conversation to advance, relative to the extent to which it aims backwards in the conversation to address what's been said. It implements, with some methodological tweaks, an approach detailed in the [paper](http://www.cs.cornell.edu/~cristian/Orientation_files/orientation-forwards-backwards.pdf),\n",
    "\n",
    "```\n",
    "Balancing Objectives in Counseling Conversations: Advancing Forwards or Looking Backwards\n",
    "Justine Zhang and Cristian Danescu-Niculescu-Mizil\n",
    "Proceedings of ACL 2020.\n",
    "\n",
    "```\n",
    "\n",
    "Beyond the measure, the notebook illustrates an approach to characterize utterances, and phrases within utterances, based on the types of replies that tend to come after it and the types of predecessors it's replying to. Interestingly, this approach can be seen as a generalization of the approach for inferring [Prompt Types](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/prompt-types/prompt-type-demo.ipynb), detailed in a [previous work](http://www.cs.cornell.edu/~cristian/Asking_too_much.html). We're exploring a more unified way to think about this approach, and an implementation in ConvoKit is forthcoming.\n",
    "\n",
    "Note that the dataset used in the paper is a collection of crisis counseling conversations, which we cannot release (see [here](https://www.crisistextline.org/data-philosophy/research-fellows) for details about access). Rather, for the demo, we use a dataset of oral arguments from the Supreme Court, extracted from the Oyez [website](https://www.oyez.org/) and available [here](https://convokit.cornell.edu/documentation/supreme.html) (we used a small subset of this corpus to perform some exploratory analysis that was reported in the appendix of the aforementioned paper). In this setting, we will characterize the orientation of things that the justices say in back-and-forths with lawyers.\n",
    "\n",
    "The Supreme Court tends to be more lexically diverse than crisis counseling conversations; the types of cases heard are much more varied than the types of situations covered in counseling conversations, while justices often have distinctive linguistic idiosyncracies. As such, while we feel that our approach for computing orientation still returns sensible output, the demo might also suggest some additional challenges that future work could tackle, like dealing with this increased lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit import Corpus\n",
    "from convokit.text_processing import TextProcessor, TextToArcs\n",
    "from convokit import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.convokitPipeline import ConvokitPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries: setting up the training data\n",
    "\n",
    "At a high level, our approach uses some \"training data\" consisting of a subset of utterances in a corpus and their associated replies and predecessors to derive per-phrase orientation scores (corresponding to the relative forwards/backwards intention of that phrase), before scoring utterances. Note that as this approach is unsupervised, \"training data\" is somewhat figurative -- we don't have supervision in the form of explicit labels in the data, but we will use information from the conversational context as a source of signal.\n",
    "\n",
    "In this section, we'll generate this training data as a subset of the larger Supreme Court corpus. (This corresponds to Figure 3A in the paper). \n",
    "\n",
    "Note that we've made some particular decisions about what to include in this subset; you may wish to play around with these choices depending on the data you've got. \n",
    "\n",
    "Note that the Supreme Court corpus is distributed as separate sub-corpora per year, since it's quite large -- in this notebook, we will demonstrate our particular choice of what training data to take on one year (2019) of data; running `get_train_subset.py` in this directory then gives you the rest of the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEMO_CORPUS_NAME = 'supreme-2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with the directory you wish to write the corpora to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '<YOUR DIRECTORY>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncomment lines, depending on whether you want to download the corpus or read from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# demo_corpus = Corpus(download(DEMO_CORPUS_NAME, data_dir=DATA_DIR))\n",
    "demo_corpus = Corpus(os.path.join(DATA_DIR, DEMO_CORPUS_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 113\n",
      "Number of Utterances: 13707\n",
      "Number of Conversations: 58\n"
     ]
    }
   ],
   "source": [
    "demo_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first preprocess the data to generate phrases for each utterance. In our case, we will use dependency tree arcs (detailed [here](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/prompt-types/prompt-type-demo.ipynb)) as phrases. (This requires us to read in dependency parses, which we've provided in the corpus but which we do not load by default.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_corpus.load_info('utterance',['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_prep_pipe = ConvokitPipeline([\n",
    "    ('arcs_per_sent', TextToArcs(output_field='arcs_per_sent')),\n",
    "    ('arcs', TextProcessor(input_field='arcs_per_sent', output_field='arcs',\n",
    "                     proc_fn=lambda sents: '\\n'.join(sents))),\n",
    "    ('wordcount', TextProcessor(input_field='parsed', output_field='wordcount',\n",
    "           proc_fn=lambda sents: sum(sum(x['tag'] != '_SP' for x in sent['toks']) for sent in sents))),\n",
    "    ('tokens', TextProcessor(input_field='parsed', output_field='tokens',\n",
    "           proc_fn=lambda sents: '\\n'.join((' '.join(x['tok'] for x in sent['toks']).strip()) for sent in sents)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_corpus = text_prep_pipe.transform(demo_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the preprocessing step outputs for each utterance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt = demo_corpus.get_utterance('24929__0_000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We'll hear argument next in Case 18-877, Allen versus Cooper. Mr. Shaffer.\n"
     ]
    }
   ],
   "source": [
    "print(utt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.retrieve_meta('wordcount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'ll_* allen_* allen_versus argument_* case_* cooper_* hear_'ll hear_* hear_allen hear_argument hear_next hear_we in_* in_case next_* next_in versus_* versus_cooper we>'ll we>* we_*\\nshaffer_*\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.retrieve_meta('arcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We 'll hear argument next in Case 18 - 877 , Allen versus Cooper .\n",
      "Mr. Shaffer .\n"
     ]
    }
   ],
   "source": [
    "print(utt.retrieve_meta('tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, our approach centers around characterizing a justice utterance in terms of the types of lawyer utterances that tend to precede or follow. More generically, we aim to characterize **source** utterances/phrases in terms of surrounding **target** utterances. In this case, the source and target utterances correspond to what justices and lawyers say, respectively; in our paper, source and target correspond to counselor and texter. (Something that would be interesting to try is to reverse roles, i.e., such that lawyers now utter the source utterances.) \n",
    "\n",
    "Our training data must contain information about justice utterances, and about the lawyer utterances that these justice utterances precede or follow. We will work towards outputting two tables, one for justice utterances and the other for lawyer utterances; each table will contain the set of component phrases in an utterance as well as the IDs of replies and predecessors.\n",
    "\n",
    "To address some of the noisiness in this corpus, we will be somewhat restrictive with the training data we subset. In particular, we will focus on characterizing justice utterances of some minimum length, that occur between lawyer utterances that are reasonably long -- that is, there is enough information about the utterance and about the context it arises in, and we are not dealing with utterances that might be small interjections or disfluencies, or very long speeches that don't reflect a back-and-forth dynamic. \n",
    "\n",
    "Therefore, we'll start by extracting a list of justice utterances and the IDs of their replies and predecessors, stored as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_context_id_df(corpus):\n",
    "    prev_df = pd.DataFrame([{'id': utt.id, 'prev_id': utt.reply_to} for utt in corpus.iter_utterances()])\n",
    "    context_id_df = prev_df.join(prev_df.drop_duplicates('prev_id').set_index('prev_id')['id'].rename('next_id'), on='id')\n",
    "    return context_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_id_df = get_context_id_df(demo_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prev_id</th>\n",
       "      <th>next_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24929__0_000</td>\n",
       "      <td>None</td>\n",
       "      <td>24929__0_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24929__0_001</td>\n",
       "      <td>24929__0_000</td>\n",
       "      <td>24929__0_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24929__0_002</td>\n",
       "      <td>24929__0_001</td>\n",
       "      <td>24929__0_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24929__0_003</td>\n",
       "      <td>24929__0_002</td>\n",
       "      <td>24929__0_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24929__0_004</td>\n",
       "      <td>24929__0_003</td>\n",
       "      <td>24929__0_005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id       prev_id       next_id\n",
       "0  24929__0_000          None  24929__0_001\n",
       "1  24929__0_001  24929__0_000  24929__0_002\n",
       "2  24929__0_002  24929__0_001  24929__0_003\n",
       "3  24929__0_003  24929__0_002  24929__0_004\n",
       "4  24929__0_004  24929__0_003  24929__0_005"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_id_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use justice utterances as source utterances, and lawyer utterances as target utterances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_filter = lambda utt: (utt.retrieve_meta('speaker_type') == 'J') and (utt.retrieve_meta('arcs') != '')\n",
    "target_filter = lambda utt: (utt.retrieve_meta('speaker_type') == 'A') and (utt.retrieve_meta('arcs') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for utt in demo_corpus.iter_utterances():\n",
    "    utt.set_info('source_filter',source_filter(utt))\n",
    "    utt.set_info('target_filter',target_filter(utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter down to our training set, we need to get sets of source and target utterances, subject to the wordcount constraints we suggested above. We'll use some dataframe operations to make this selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt_df = demo_corpus.get_attribute_table('utterance', ['wordcount', 'source_filter','target_filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_filter</th>\n",
       "      <th>target_filter</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24929__0_000</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_001</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_002</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_003</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_004</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source_filter  target_filter  wordcount\n",
       "id                                                   \n",
       "24929__0_000           True          False         18\n",
       "24929__0_001          False           True        390\n",
       "24929__0_002           True          False         45\n",
       "24929__0_003          False           True        161\n",
       "24929__0_004           True          False          4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_context_df = context_id_df.join(utt_df, on='id')\\\n",
    "    .join(utt_df, on='prev_id', rsuffix='_prev')\\\n",
    "    .join(utt_df, on='next_id', rsuffix='_next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prev_id</th>\n",
       "      <th>next_id</th>\n",
       "      <th>source_filter</th>\n",
       "      <th>target_filter</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>source_filter_prev</th>\n",
       "      <th>target_filter_prev</th>\n",
       "      <th>wordcount_prev</th>\n",
       "      <th>source_filter_next</th>\n",
       "      <th>target_filter_next</th>\n",
       "      <th>wordcount_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24929__0_000</td>\n",
       "      <td>None</td>\n",
       "      <td>24929__0_001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24929__0_001</td>\n",
       "      <td>24929__0_000</td>\n",
       "      <td>24929__0_002</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>390</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24929__0_002</td>\n",
       "      <td>24929__0_001</td>\n",
       "      <td>24929__0_003</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>390.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24929__0_003</td>\n",
       "      <td>24929__0_002</td>\n",
       "      <td>24929__0_004</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>161</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>45.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24929__0_004</td>\n",
       "      <td>24929__0_003</td>\n",
       "      <td>24929__0_005</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>161.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id       prev_id       next_id  source_filter  target_filter  \\\n",
       "0  24929__0_000          None  24929__0_001           True          False   \n",
       "1  24929__0_001  24929__0_000  24929__0_002          False           True   \n",
       "2  24929__0_002  24929__0_001  24929__0_003           True          False   \n",
       "3  24929__0_003  24929__0_002  24929__0_004          False           True   \n",
       "4  24929__0_004  24929__0_003  24929__0_005           True          False   \n",
       "\n",
       "   wordcount source_filter_prev target_filter_prev  wordcount_prev  \\\n",
       "0         18                NaN                NaN             NaN   \n",
       "1        390               True              False            18.0   \n",
       "2         45              False               True           390.0   \n",
       "3        161               True              False            45.0   \n",
       "4          4              False               True           161.0   \n",
       "\n",
       "  source_filter_next target_filter_next  wordcount_next  \n",
       "0              False               True           390.0  \n",
       "1               True              False            45.0  \n",
       "2              False               True           161.0  \n",
       "3               True              False             4.0  \n",
       "4              False               True             7.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_context_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want source utterances that are reasonably (but not too) long, and that occur between reasonably long target utterances. The following min/max wordcounts roughly correspond to 25th and 50th percentiles (these are parameters that could be tweaked); selecting on them produces tables listing the source and target utterances we will consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_wc_source = 10\n",
    "max_wc_source = 50\n",
    "min_wc_target = 10\n",
    "max_wc_target = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_df = full_context_df[full_context_df.source_filter\n",
    "           & full_context_df.wordcount.between(min_wc_source, max_wc_source)\n",
    "           & full_context_df.wordcount_prev.between(min_wc_target, max_wc_target)\n",
    "           & full_context_df.wordcount_next.between(min_wc_target, max_wc_target)].set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_df = full_context_df[full_context_df.target_filter\n",
    "   & full_context_df.wordcount.between(min_wc_target, max_wc_target)].set_index('id')\n",
    "source_df = source_df[source_df.prev_id.isin(target_df.index)\n",
    "         & source_df.next_id.isin(target_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2087"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining these tables with tables of utterance phrasings gives us the full training data we will subsequently use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_cols = ['arcs','tokens']\n",
    "text_df = demo_corpus.get_attribute_table('utterance',text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_df = source_df[['prev_id','next_id']].join(text_df)\n",
    "target_df = target_df[[]].join(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_id</th>\n",
       "      <th>next_id</th>\n",
       "      <th>arcs</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24929__0_014</th>\n",
       "      <td>24929__0_013</td>\n",
       "      <td>24929__0_015</td>\n",
       "      <td>but&gt;* but&gt;how could_* going_* going_rules goin...</td>\n",
       "      <td>But how -- how could -- how could we have the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_016</th>\n",
       "      <td>24929__0_015</td>\n",
       "      <td>24929__0_017</td>\n",
       "      <td>'re_* asking_'re asking_* asking_basically ask...</td>\n",
       "      <td>So , basically , you 're asking us to overrule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_054</th>\n",
       "      <td>24929__0_053</td>\n",
       "      <td>24929__0_055</td>\n",
       "      <td>a_* by_* by_government by_state constitutional...</td>\n",
       "      <td>Every -- every infringement is a violate -- ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_082</th>\n",
       "      <td>24929__0_081</td>\n",
       "      <td>24929__0_083</td>\n",
       "      <td>all&gt;* all_* california_* over_* over_all over_...</td>\n",
       "      <td>All over California .\\nWhy does n't California...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_086</th>\n",
       "      <td>24929__0_085</td>\n",
       "      <td>24929__0_087</td>\n",
       "      <td>'m_* about_* about_copyright copyright_* i&gt;'m ...</td>\n",
       "      <td>I 'm not talking about copyright .\\nI 'm talki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   prev_id       next_id  \\\n",
       "id                                         \n",
       "24929__0_014  24929__0_013  24929__0_015   \n",
       "24929__0_016  24929__0_015  24929__0_017   \n",
       "24929__0_054  24929__0_053  24929__0_055   \n",
       "24929__0_082  24929__0_081  24929__0_083   \n",
       "24929__0_086  24929__0_085  24929__0_087   \n",
       "\n",
       "                                                           arcs  \\\n",
       "id                                                                \n",
       "24929__0_014  but>* but>how could_* going_* going_rules goin...   \n",
       "24929__0_016  're_* asking_'re asking_* asking_basically ask...   \n",
       "24929__0_054  a_* by_* by_government by_state constitutional...   \n",
       "24929__0_082  all>* all_* california_* over_* over_all over_...   \n",
       "24929__0_086  'm_* about_* about_copyright copyright_* i>'m ...   \n",
       "\n",
       "                                                         tokens  \n",
       "id                                                               \n",
       "24929__0_014  But how -- how could -- how could we have the ...  \n",
       "24929__0_016  So , basically , you 're asking us to overrule...  \n",
       "24929__0_054  Every -- every infringement is a violate -- ev...  \n",
       "24929__0_082  All over California .\\nWhy does n't California...  \n",
       "24929__0_086  I 'm not talking about copyright .\\nI 'm talki...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arcs</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24929__0_013</th>\n",
       "      <td>argument_* argument_kagan argument_that be_* b...</td>\n",
       "      <td>It would be certainly open to folks in patent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_015</th>\n",
       "      <td>be_* be_prediction be_that be_would my_* predi...</td>\n",
       "      <td>That would be my prediction .\\nMy prediction i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_017</th>\n",
       "      <td>'m_* alito_* alito_justice alito_think asking_...</td>\n",
       "      <td>I 'm asking this Court to follow Katz , Justic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_019</th>\n",
       "      <td>basis_* basis_for basis_the florida_* for_* fo...</td>\n",
       "      <td>I think it -- it overruled -- it overruled the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929__0_025</th>\n",
       "      <td>court_* court_the decide_* decide_court decide...</td>\n",
       "      <td>Well , Justice Kavanaugh , obviously , the Cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           arcs  \\\n",
       "id                                                                \n",
       "24929__0_013  argument_* argument_kagan argument_that be_* b...   \n",
       "24929__0_015  be_* be_prediction be_that be_would my_* predi...   \n",
       "24929__0_017  'm_* alito_* alito_justice alito_think asking_...   \n",
       "24929__0_019  basis_* basis_for basis_the florida_* for_* fo...   \n",
       "24929__0_025  court_* court_the decide_* decide_court decide...   \n",
       "\n",
       "                                                         tokens  \n",
       "id                                                               \n",
       "24929__0_013  It would be certainly open to folks in patent ...  \n",
       "24929__0_015  That would be my prediction .\\nMy prediction i...  \n",
       "24929__0_017  I 'm asking this Court to follow Katz , Justic...  \n",
       "24929__0_019  I think it -- it overruled -- it overruled the...  \n",
       "24929__0_025  Well , Justice Kavanaugh , obviously , the Cou...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate the rest of the training data by running `get_train_subset.py` in the same directory as this. The variables at the top of the file can be tweaked and played around with, per the comments in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read all of the training data from across the entire Supreme Court corpus. (`MIN_YEAR` and `MAX_YEAR` can be adjusted if you wish to only examine a subset, or if you're short on memory.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_YEAR = 1955\n",
    "MAX_YEAR = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dfs = []\n",
    "target_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year in range(MIN_YEAR, MAX_YEAR + 1):\n",
    "    source_dfs.append(pd.read_csv(os.path.join(DATA_DIR, 'supreme-' + str(year) + '.source.tsv'), sep='\\t', index_col=0))\n",
    "    target_dfs.append(pd.read_csv(os.path.join(DATA_DIR, 'supreme-' + str(year) + '.target.tsv'), sep='\\t', index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_df = pd.concat(source_dfs)\n",
    "target_df = pd.concat(target_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how many source and target utterances we have. \n",
    "\n",
    "(A note: these numbers are not equivalent because we were slightly permissive about which target utterances to include; while we enforce that source utterances must be surrounded by reasonably-long target utterances, the only restriction we place on target utterances is that they're reasonably long, without imposing these contextual constraints.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91924"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372268"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving vector representations of target utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step of our approach is to derive vector representations of target (i.e., lawyer) utterances, corresponding to Figure 3B in the paper. Per the paper, we will:\n",
    "* derive tf-idf vectors of target utterances;\n",
    "* use singular value decomposition to get low-dimensional representations of utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting tf-idf vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some details:\n",
    "* MIN_DF and MAX_DF correspond to the min_df and max_df arguments passed to `sklearn`'s `TfidfVectorizer`, controling how frequently phrases need to appear to be counted in our vocabulary. In the Supreme Court corpus, it might be safe to set MIN_DF fairly high; otherwise the vocabulary could contain many phrases that are specific to particular cases.\n",
    "* We found that for each phrase, normalizing the tf-idf weight across all the utterances the phrases appear in produced slightly nicer output. The intuition might be to think of these next few steps as characterizing _phrases_, rather than utterances. `ColNormedTfidf` is a custom transformer that accomplishes this (and stores norms so that new data can later be similarly transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_DF = 100\n",
    "MAX_DF = 1.\n",
    "MAX_FEATURES = 2000\n",
    "\n",
    "TEXT_COL = 'arcs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColNormedTfidf(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, norm_cols=True, **kwargs):\n",
    "        self.tfidf_model = TfidfVectorizer(token_pattern=r'(?u)(\\S+)',**kwargs)\n",
    "        self.norm_cols = norm_cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        tfidf_vects_raw = self.tfidf_model.fit_transform(X)\n",
    "        self.tfidf_norms = sparse.linalg.norm(tfidf_vects_raw, axis=0)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        tfidf_vects_raw = self.tfidf_model.transform(X)\n",
    "        if self.norm_cols:\n",
    "            tfidf_vect = tfidf_vects_raw.T / self.tfidf_norms[:,np.newaxis]\n",
    "        else:\n",
    "            tfidf_vect = tfidf_vects_raw.T / np.ones_like(self.tfidf_norms[:,np.newaxis])\n",
    "        return tfidf_vect\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.tfidf_model.get_feature_names()\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.tfidf_model.get_params(deep=deep)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        return self.tfidf_model.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_tfidf_obj = ColNormedTfidf(max_features=MAX_FEATURES, binary=True,\n",
    "                                 min_df=MIN_DF, max_df=MAX_DF)\n",
    "target_tfidf_vect = target_tfidf_obj.fit_transform(target_df[TEXT_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 372268)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting low-dimensional representations using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting SVD_DIMS higher or lower roughly toggles the extent to which you capture higher-level conceptual classes, versus more direct lexical matches. In our paper, we used a higher dimension for the counseling data than what we've chosen here: the intuition is again to work around the increased lexical diversity and mitigate the possibility of capturing case-specific information. \n",
    "\n",
    "An in-the-weeds spoiler alert: This is worth playing around with -- higher values of SVD_DIMS results in more forwards-oriented phrasings later on. (an intuition is that more sensitivity to lexical differences = more sensitive to noise in the varied things that lawyers say that justices respond to; whereas lawyers, perhaps out of procedure or respect, tend to have more well-defined responses to justice prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVD_DIMS = 15\n",
    "RANDOM_STATE = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svd_obj(vect, svd_dims, random_state=RANDOM_STATE):\n",
    "    U,s,V = randomized_svd(vect, n_components=svd_dims, random_state=random_state)\n",
    "    return {'U': U, 's': s, 'V': V.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_svd_obj = get_svd_obj(target_tfidf_vect, SVD_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.96525955, 2.22446003, 2.11388959, 2.05197851, 2.00981703,\n",
       "       1.98249565, 1.9364843 , 1.92670078, 1.91136899, 1.89870573,\n",
       "       1.88872119, 1.84319579, 1.83926558, 1.82746449, 1.82167165])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_svd_obj['s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For text, the first SVD dimension typically corresponds to word/phrase frequency. Since we would like embeddings to be close together on the basis of semantic, rather than numeric similarity, we will drop the first dimension via the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def snip(vects, dim=None, snip_first_dim=True):\n",
    "    if dim is None:\n",
    "        dim = vects.shape[1]\n",
    "    return normalize(vects[:,int(snip_first_dim):dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing source phrases in terms of target utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, we've produced representations of target utterances in the training data. We now want to work towards producing representations of the _source_ phrases that follow or precede these target utterances -- recall that what we're after is some characterization of justices, not lawyers.\n",
    "\n",
    "The high-level idea we will subsequently implement is to represent a source phrase in terms of the target utterances that follow source utterances with that phrase in the training data, e.g., all lawyer responses to utterances where the justice says \"[what's the] difference between...\" -- we'll refer to this as a _forwards_ representation. \n",
    "\n",
    "Likewise, we'll compute a _backwards_ representation of a source phrase in terms of the target utterances that precede source utterances with that phrase, e.g., all lawyer utterances to which the justice responds \"[what's the] difference between\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires us to keep track of which source utterances are associated in with which target utterances in either direction -- here, we'll keep track of pairs of indices: (index of source utterance in an  array; index of corresponding target utterance in an array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_df['mtx_idx'] = np.arange(len(source_df))\n",
    "target_df['mtx_idx'] = np.arange(len(target_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_df = source_df.join(target_df.mtx_idx, on='prev_id', rsuffix='_prev')\\\n",
    "    .join(target_df.mtx_idx, on='next_id', rsuffix='_next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_idx_mapping = source_df[['mtx_idx','mtx_idx_next']].values # forwards\n",
    "bk_idx_mapping = source_df[['mtx_idx','mtx_idx_prev']].values # backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these associations between utterances:\n",
    "1. we will essentially _project_ (in a linear algebra sense) a source phrase into the low-dimensional space of target utterances (Figure 3C), to derive \"prototypical representations\" of source phrases in terms of their expected responses/predecessors. In practice, this amounts to taking a _weighted average_ of target utterances; here we use tf-idf weights normalized by phrase (similar to how we represented target utterances above), and rescale each dimension by the singular values from the preceding SVD.\n",
    "2. given these prototypical representations, we compute a _range_ for each phrase that quantifies the extent to which expected replies (or predecessors) are well-defined and similar to each other, or varied and spread out (Figure 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossEmbed:\n",
    "    \n",
    "    def __init__(self, source_vects, target_embeddings, target_s, idx_mapping, snip_first_dim=True):\n",
    "        \n",
    "        self.source_vects = source_vects\n",
    "        self.target_embeddings = target_embeddings\n",
    "        self.target_s = target_s\n",
    "        \n",
    "        source_subset = self.source_vects[:, idx_mapping[:,0]]\n",
    "        target_subset = self.target_embeddings[idx_mapping[:, 1]]\n",
    "        \n",
    "        # deriving central point for a phrase\n",
    "        self.term_embeddings = source_subset * target_subset / target_s\n",
    "        \n",
    "        # computing range for a phrase\n",
    "        full_dists = cosine_distances(\n",
    "            snip(self.term_embeddings, snip_first_dim=snip_first_dim),\n",
    "            snip(target_subset, snip_first_dim=snip_first_dim)\n",
    "        )\n",
    "        weights = normalize(np.array(source_subset > 0), norm='l1')\n",
    "        clipped_dists = np.clip(full_dists, None, 1)\n",
    "        \n",
    "        self.term_ranges = (clipped_dists * weights).sum(axis=1)\n",
    "        \n",
    "    # deriving embeddings of utterances. we won't use this, but it corresponds to the PromptType methodology \n",
    "    # and we might as well include it.\n",
    "    def embed_docs(self, doc_vect):\n",
    "        return doc_vect.T * self.term_embeddings / self.target_s\n",
    "    \n",
    "    # computing ranges of utterances.\n",
    "    def compute_docs_range(self, doc_vect):\n",
    "        return np.dot(normalize(doc_vect.T, norm='l1'), self.term_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(computing tf-idf weights for our weighted average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_tfidf_obj = ColNormedTfidf(max_features=MAX_FEATURES, binary=True,\n",
    "                                 min_df=MIN_DF, max_df=MAX_DF)\n",
    "source_tfidf_vect = source_tfidf_obj.fit_transform(source_df[TEXT_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = np.array(source_tfidf_vect > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing source phrases in terms of replies (forwards):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_obj = CrossEmbed(source_tfidf_vect, target_svd_obj['V'], target_svd_obj['s'], fw_idx_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing source phrases in terms of predecessors (backwards):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bk_obj = CrossEmbed(source_tfidf_vect, target_svd_obj['V'], target_svd_obj['s'], bk_idx_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this procedure, we now have two quantities that characterize each source phrase -- a forwards and a backwards range. Subtracting these ranges then gives us the phrase's orientation (Figure 3E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orientation = bk_obj.term_ranges - fw_obj.term_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring orientation of phrases from justice orientations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect these phrases to see what our measure reflects in the Supreme Court corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orientation_df = pd.DataFrame({\n",
    "    'index': source_tfidf_obj.get_feature_names(),\n",
    "    'orientation': orientation,\n",
    "    'fw_range': fw_obj.term_ranges,\n",
    "    'bk_range': bk_obj.term_ranges,\n",
    "    'n': frequency\n",
    "}).set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, most justice phrasings have a positive orientation -- that is, they're more forwards oriented, so we generally have a stronger sense of what replies they prompt than what predecessors they follow. This might make sense thinking about the power dynamics in the Supreme Court, it's believable that justices use more words that push lawyers towards specific replies than that reflect on what the lawyers have said; an alternative explanation is that lawyers say very diverse things for justices to reply to (such that backwards-ranges are more spread out), but justices often structure their questions to provoke particular forms of answers (such that there is greater lexical cohesion among lawyer responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    0.639\n",
       "-1.0    0.361\n",
       "Name: orientation, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(orientation_df.orientation).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the most backwards-oriented phrases. We see a few more \"topical\" phrases (commission, prosecution, employees), perhaps reflecting points that justices often pick up on in what a lawyer has said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientation</th>\n",
       "      <th>fw_range</th>\n",
       "      <th>bk_range</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>available_*</th>\n",
       "      <td>-0.068312</td>\n",
       "      <td>0.875046</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commission_*</th>\n",
       "      <td>-0.067559</td>\n",
       "      <td>0.852920</td>\n",
       "      <td>0.785361</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_for</th>\n",
       "      <td>-0.061511</td>\n",
       "      <td>0.846946</td>\n",
       "      <td>0.785435</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specific_*</th>\n",
       "      <td>-0.060206</td>\n",
       "      <td>0.875184</td>\n",
       "      <td>0.814978</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and&gt;it</th>\n",
       "      <td>-0.059189</td>\n",
       "      <td>0.855133</td>\n",
       "      <td>0.795944</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prosecution_*</th>\n",
       "      <td>-0.059091</td>\n",
       "      <td>0.825940</td>\n",
       "      <td>0.766848</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employees_*</th>\n",
       "      <td>-0.054333</td>\n",
       "      <td>0.767615</td>\n",
       "      <td>0.713282</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laughter_*</th>\n",
       "      <td>-0.053807</td>\n",
       "      <td>0.832771</td>\n",
       "      <td>0.778964</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_order</th>\n",
       "      <td>-0.053699</td>\n",
       "      <td>0.873568</td>\n",
       "      <td>0.819868</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand_that</th>\n",
       "      <td>-0.053405</td>\n",
       "      <td>0.880014</td>\n",
       "      <td>0.826609</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_the</th>\n",
       "      <td>-0.052443</td>\n",
       "      <td>0.812756</td>\n",
       "      <td>0.760313</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency_*</th>\n",
       "      <td>-0.052310</td>\n",
       "      <td>0.798216</td>\n",
       "      <td>0.745906</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all&gt;*</th>\n",
       "      <td>-0.051825</td>\n",
       "      <td>0.882862</td>\n",
       "      <td>0.831037</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_do</th>\n",
       "      <td>-0.051218</td>\n",
       "      <td>0.884045</td>\n",
       "      <td>0.832826</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commission_the</th>\n",
       "      <td>-0.050825</td>\n",
       "      <td>0.837871</td>\n",
       "      <td>0.787047</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which&gt;*</th>\n",
       "      <td>-0.050679</td>\n",
       "      <td>0.866757</td>\n",
       "      <td>0.816078</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outside_*</th>\n",
       "      <td>-0.047459</td>\n",
       "      <td>0.846150</td>\n",
       "      <td>0.798691</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_*</th>\n",
       "      <td>-0.045307</td>\n",
       "      <td>0.849193</td>\n",
       "      <td>0.803885</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habeas_*</th>\n",
       "      <td>-0.043897</td>\n",
       "      <td>0.790778</td>\n",
       "      <td>0.746881</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims_*</th>\n",
       "      <td>-0.043514</td>\n",
       "      <td>0.841856</td>\n",
       "      <td>0.798342</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earlier_*</th>\n",
       "      <td>-0.043433</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.828850</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_it</th>\n",
       "      <td>-0.042727</td>\n",
       "      <td>0.880942</td>\n",
       "      <td>0.838215</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>union_*</th>\n",
       "      <td>-0.041612</td>\n",
       "      <td>0.764056</td>\n",
       "      <td>0.722444</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sort_*</th>\n",
       "      <td>-0.041548</td>\n",
       "      <td>0.856325</td>\n",
       "      <td>0.814777</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judges_*</th>\n",
       "      <td>-0.040994</td>\n",
       "      <td>0.856036</td>\n",
       "      <td>0.815042</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 orientation  fw_range  bk_range    n\n",
       "index                                                \n",
       "available_*        -0.068312  0.875046  0.806734  317\n",
       "commission_*       -0.067559  0.852920  0.785361  656\n",
       "is_for             -0.061511  0.846946  0.785435  256\n",
       "specific_*         -0.060206  0.875184  0.814978  342\n",
       "and>it             -0.059189  0.855133  0.795944  329\n",
       "prosecution_*      -0.059091  0.825940  0.766848  257\n",
       "employees_*        -0.054333  0.767615  0.713282  318\n",
       "laughter_*         -0.053807  0.832771  0.778964  683\n",
       "in_order           -0.053699  0.873568  0.819868  410\n",
       "understand_that    -0.053405  0.880014  0.826609  392\n",
       "claim_the          -0.052443  0.812756  0.760313  293\n",
       "agency_*           -0.052310  0.798216  0.745906  398\n",
       "all>*              -0.051825  0.882862  0.831037  697\n",
       "mean_do            -0.051218  0.884045  0.832826  463\n",
       "commission_the     -0.050825  0.837871  0.787047  572\n",
       "which>*            -0.050679  0.866757  0.816078  323\n",
       "outside_*          -0.047459  0.846150  0.798691  265\n",
       "class_*            -0.045307  0.849193  0.803885  333\n",
       "habeas_*           -0.043897  0.790778  0.746881  268\n",
       "claims_*           -0.043514  0.841856  0.798342  417\n",
       "earlier_*          -0.043433  0.872283  0.828850  275\n",
       "to_it              -0.042727  0.880942  0.838215  326\n",
       "union_*            -0.041612  0.764056  0.722444  584\n",
       "sort_*             -0.041548  0.856325  0.814777  487\n",
       "judges_*           -0.040994  0.856036  0.815042  264"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation_df[orientation_df.n >= 250].sort_values('orientation').head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the most forwards-oriented phrases. Interestingly (and perhaps promisingly), many sound like fragments of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientation</th>\n",
       "      <th>fw_range</th>\n",
       "      <th>bk_range</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in_brief</th>\n",
       "      <td>0.145374</td>\n",
       "      <td>0.654769</td>\n",
       "      <td>0.800142</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief_your</th>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.676582</td>\n",
       "      <td>0.817695</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anything</th>\n",
       "      <td>0.115232</td>\n",
       "      <td>0.707332</td>\n",
       "      <td>0.822564</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be_what</th>\n",
       "      <td>0.113340</td>\n",
       "      <td>0.723905</td>\n",
       "      <td>0.837245</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_issue</th>\n",
       "      <td>0.109660</td>\n",
       "      <td>0.715291</td>\n",
       "      <td>0.824952</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difference_any</th>\n",
       "      <td>0.108340</td>\n",
       "      <td>0.742786</td>\n",
       "      <td>0.851126</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make_would</th>\n",
       "      <td>0.103676</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>0.852132</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_really</th>\n",
       "      <td>0.103238</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be_you</th>\n",
       "      <td>0.102827</td>\n",
       "      <td>0.749427</td>\n",
       "      <td>0.852254</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear_*</th>\n",
       "      <td>0.097677</td>\n",
       "      <td>0.652663</td>\n",
       "      <td>0.750340</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of_appeals</th>\n",
       "      <td>0.097252</td>\n",
       "      <td>0.614031</td>\n",
       "      <td>0.711283</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where&gt;*</th>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.725915</td>\n",
       "      <td>0.817801</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_where</th>\n",
       "      <td>0.091748</td>\n",
       "      <td>0.728747</td>\n",
       "      <td>0.820495</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suppose&gt;*</th>\n",
       "      <td>0.090441</td>\n",
       "      <td>0.721628</td>\n",
       "      <td>0.812069</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief_*</th>\n",
       "      <td>0.088758</td>\n",
       "      <td>0.702960</td>\n",
       "      <td>0.791717</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raised_*</th>\n",
       "      <td>0.088452</td>\n",
       "      <td>0.689256</td>\n",
       "      <td>0.777707</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appeals_*</th>\n",
       "      <td>0.085380</td>\n",
       "      <td>0.629112</td>\n",
       "      <td>0.714492</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_record</th>\n",
       "      <td>0.084385</td>\n",
       "      <td>0.588508</td>\n",
       "      <td>0.672893</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difference_the</th>\n",
       "      <td>0.084344</td>\n",
       "      <td>0.729926</td>\n",
       "      <td>0.814270</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would&gt;you</th>\n",
       "      <td>0.083218</td>\n",
       "      <td>0.786076</td>\n",
       "      <td>0.869295</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have&gt;*</th>\n",
       "      <td>0.081759</td>\n",
       "      <td>0.772656</td>\n",
       "      <td>0.854415</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said_if</th>\n",
       "      <td>0.080972</td>\n",
       "      <td>0.731893</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many_how</th>\n",
       "      <td>0.080834</td>\n",
       "      <td>0.681081</td>\n",
       "      <td>0.761915</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difference_between</th>\n",
       "      <td>0.080253</td>\n",
       "      <td>0.749194</td>\n",
       "      <td>0.829447</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would_it</th>\n",
       "      <td>0.078910</td>\n",
       "      <td>0.738195</td>\n",
       "      <td>0.817105</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    orientation  fw_range  bk_range     n\n",
       "index                                                    \n",
       "in_brief               0.145374  0.654769  0.800142   313\n",
       "brief_your             0.141113  0.676582  0.817695   338\n",
       "is_anything            0.115232  0.707332  0.822564   288\n",
       "be_what                0.113340  0.723905  0.837245   363\n",
       "is_issue               0.109660  0.715291  0.824952   270\n",
       "difference_any         0.108340  0.742786  0.851126   267\n",
       "make_would             0.103676  0.748457  0.852132   266\n",
       "is_really              0.103238  0.767692  0.870930   284\n",
       "be_you                 0.102827  0.749427  0.852254   368\n",
       "hear_*                 0.097677  0.652663  0.750340   292\n",
       "of_appeals             0.097252  0.614031  0.711283  1094\n",
       "where>*                0.091886  0.725915  0.817801   556\n",
       "is_where               0.091748  0.728747  0.820495   433\n",
       "suppose>*              0.090441  0.721628  0.812069   591\n",
       "brief_*                0.088758  0.702960  0.791717   663\n",
       "raised_*               0.088452  0.689256  0.777707   372\n",
       "appeals_*              0.085380  0.629112  0.714492  1171\n",
       "in_record              0.084385  0.588508  0.672893   565\n",
       "difference_the         0.084344  0.729926  0.814270   376\n",
       "would>you              0.083218  0.786076  0.869295   462\n",
       "have>*                 0.081759  0.772656  0.854415   262\n",
       "said_if                0.080972  0.731893  0.812865   250\n",
       "many_how               0.080834  0.681081  0.761915   430\n",
       "difference_between     0.080253  0.749194  0.829447   308\n",
       "would_it               0.078910  0.738195  0.817105   535"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation_df[orientation_df.n >= 250].sort_values('orientation', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My take is that while the forwards-oriented examples seem pretty clearly pointed forwards, in that they sound like questions prompting particular types of answers (like in the Prompt Types intuition), the backwards-oriented examples are a little more muddied. Perhaps interpreting them requires a bit more domain knowledge about the Supreme Court, or they tend to be more contingent in the particularities of various cases (which, after all, justices have to address) -- future work could better address such contingencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to better interpret orientation, and more broadly, what these embeddings are telling us, is to look at source and target phrases that are mapped to similar regions of the latent space. By construction, it should be the case that if a representation of a source phrase, under the forwards mapping, is close to a representation of a target phrase, that target phrase tended to be in a reply to that source phrase in the training data. Likewise, if two embeddings are close together under the backwards mapping, then that target phrase would tend to precede the source phrase in the training data. \n",
    "\n",
    "As such, for each source phrase, we inspect nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cross_embed_neighbors(source_term_embeds, target_term_embeds, source_terms, target_terms,\n",
    "                             snip_first_dim=True):\n",
    "    neighbors = cosine_distances(snip(source_term_embeds, snip_first_dim=snip_first_dim),\n",
    "                                snip(target_term_embeds, snip_first_dim=snip_first_dim))\n",
    "    return pd.DataFrame(data=neighbors, index=source_terms, columns=target_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_neighbors = get_cross_embed_neighbors(fw_obj.term_embeddings, target_svd_obj['U'], source_tfidf_obj.get_feature_names(),\n",
    "                                        target_tfidf_obj.get_feature_names())\n",
    "bk_neighbors = get_cross_embed_neighbors(bk_obj.term_embeddings, target_svd_obj['U'], source_tfidf_obj.get_feature_names(),\n",
    "                                        target_tfidf_obj.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a forwards-oriented phrase is `difference_between`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08025254053242692"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation_df.loc['difference_between'].orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting nearest neighbors of the forwards embedding -- i.e., things we expect lawyers to say in response to a justice utterance containing \"difference_between\", based on the training data -- we see that the phrase (unsurprisingly) prompts lawyers to draw contrasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_difference       0.108667\n",
       "difference_the      0.119686\n",
       "is_where            0.121033\n",
       "difference_*        0.135345\n",
       "difference_a        0.150741\n",
       "distinction_*       0.180849\n",
       "between_*           0.190600\n",
       "significant_*       0.192622\n",
       "is_are              0.239439\n",
       "speech_*            0.241334\n",
       "discrimination_*    0.255033\n",
       "is_different        0.267632\n",
       "is_there            0.269909\n",
       "substantial_*       0.273739\n",
       "requirement_*       0.282649\n",
       "real_*              0.295133\n",
       "injury_*            0.297816\n",
       "different_*         0.299115\n",
       "serious_*           0.311851\n",
       "basis_a             0.314357\n",
       "Name: difference_between, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw_neighbors.loc['difference_between'].sort_values().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cohesion is arguably less visible if we look at nearest neighbors of the backwards embedding -- i.e., things that lawyers said that justices tended to respond to with utterances containing \"difference_between\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "there_*           0.228998\n",
       "difference_a      0.255950\n",
       "question_no       0.261286\n",
       "is_there          0.281736\n",
       "difference_*      0.283994\n",
       "relevant_*        0.296001\n",
       "question_about    0.316051\n",
       "'s_there          0.316707\n",
       "there>*           0.324570\n",
       "doubt_*           0.325439\n",
       "is_difference     0.328573\n",
       "but>there         0.336422\n",
       "'s_question       0.337620\n",
       "difference_the    0.351272\n",
       "and>there         0.351567\n",
       "sense_the         0.352142\n",
       "serious_*         0.354075\n",
       "distinction_*     0.363075\n",
       "question_a        0.370353\n",
       "possibility_*     0.371970\n",
       "Name: difference_between, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_neighbors.loc['difference_between'].sort_values().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still seems that justices tend to ask for contrasts after lawyers articulate contrasts, but this is certainly not a hard-and-fast rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a backwards-oriented phrase is `specific_*`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06020567193337334"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation_df.loc['specific_*'].orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at nearest backwards neighbors, we see lawyer phrases which seem to locate specific aspects of e.g., a statute, a requirement, some other precedent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_which            0.188142\n",
       "specific_*          0.188767\n",
       "is_one              0.197095\n",
       "is_to               0.216025\n",
       "is_in               0.244239\n",
       "discrimination_*    0.245091\n",
       "itself_*            0.251703\n",
       "is_where            0.278767\n",
       "in_statute          0.284501\n",
       "separate_*          0.293673\n",
       "is_the              0.295271\n",
       "is_here             0.297449\n",
       "process_the         0.302387\n",
       "is_there            0.303016\n",
       "is_*                0.307968\n",
       "is_now              0.311984\n",
       "requirement_*       0.313694\n",
       "is_statute          0.314290\n",
       "requirement_the     0.317387\n",
       "of_section          0.322219\n",
       "Name: specific_*, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_neighbors.loc['specific_*'].sort_values().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is less clear in the forwards direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaking_*       0.267105\n",
       "certain_*        0.271000\n",
       "aware_of         0.317548\n",
       "are_there        0.321637\n",
       "aware_*          0.324101\n",
       "sure_*           0.340423\n",
       "'m_not           0.343878\n",
       "'m_sure          0.345877\n",
       "of_that          0.349148\n",
       "'m_i             0.360995\n",
       "am_sure          0.362645\n",
       "am_not           0.366701\n",
       "are_well         0.366811\n",
       "'m_sorry         0.376976\n",
       "sorry_*          0.378896\n",
       "completely_*     0.388760\n",
       "am_i             0.392444\n",
       "understand_*     0.401210\n",
       "understand_i     0.402399\n",
       "question_your    0.402740\n",
       "Name: specific_*, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw_neighbors.loc['specific_*'].sort_values().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-level orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can characterize the orientation of a sentence by aggregating phrase-level orientation across all the phrases in a sentence. For now, we will simply compute a tf-idf weighted average of phrase-level orientation. Note that at this level of aggregation, the measure gets a lot messier, especially given the relatively noisy oral argument setting. \n",
    "\n",
    "We can, of course, go beyond sentences to look at entire utterances -- some more work might need to be done here, since utterances in oral arguments can get quite long and cover a lot of ground (contrasting short text messages in the crisis counseling data used in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while we used the subsetted training data to compute orientation, we are not bound to the same constraints in computing the orientation of a new utterance -- i.e., an utterance has a well-defined orientation regardless of how long or short its replies or predecessors are. This speaks to the intuition that our embeddings aim to represent some aspect of a speaker's _intention_ based on the phrases they use, rather than what _actually happens_ in a conversation.\n",
    "\n",
    "As such, we will compute orientation for all sentences uttered by justices in our demo corpus from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get sentence-level representations of utterances\n",
    "arcs_per_sentence = []\n",
    "for utt in demo_corpus.iter_utterances():\n",
    "    if utt.retrieve_meta('source_filter'):\n",
    "        sents = utt.retrieve_meta('arcs').split('\\n')\n",
    "        tok_sents = utt.retrieve_meta('tokens').split('\\n')\n",
    "        for i, (sent, tok_sent) in enumerate(zip(sents, tok_sents)):\n",
    "            arcs_per_sentence.append({'id': '%s__%02d' % (utt.id, i),\n",
    "                                     'n_tokens': len(tok_sent.split()),\n",
    "                                     'arcs': sent,\n",
    "                                     'tokens': tok_sent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_sent_df = pd.DataFrame(arcs_per_sentence).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_sent_vects = source_tfidf_obj.transform(arc_sent_df.arcs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_sent_fw_range = fw_obj.compute_docs_range(arc_sent_vects)\n",
    "arc_sent_bk_range = bk_obj.compute_docs_range(arc_sent_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_sent_df['orientation'] = arc_sent_bk_range - arc_sent_fw_range\n",
    "arc_sent_df['fw'] = arc_sent_fw_range\n",
    "arc_sent_df['bk'] = arc_sent_bk_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with phrases, we see that most justice sentences are forwards-oriented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    0.783507\n",
       "-1.0    0.196412\n",
       " 0.0    0.020081\n",
       "Name: orientation, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(arc_sent_df.orientation).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we display a selection of the most forwards and most backwards-oriented sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_sent_subset = arc_sent_df[arc_sent_df.n_tokens >= 15].drop_duplicates('arcs') # for interpretability, examining reasonably-long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Now , if we 're going to be extending the -- the -- the understanding of what sex encompasses , and I know your argument --\",\n",
       "       'But before counsel leave , I would like to invite Mr. Clement to return to the lectern .',\n",
       "       'And obviously I can use the same example with race , which is famous .',\n",
       "       \"Normally , we use law enforcement investigative tools like subpoenas to investigate known crimes and not to pursue individuals ' defined crimes .\",\n",
       "       'But AEDPA was intended to move habeas petitions along quickly and is full of deadlines .',\n",
       "       'And -- and RFRA provides a backstop on that , but even beyond RFRA , in the ACA , Congress has delegated to the agency .',\n",
       "       'Mr. Feigin , everybody has authority to spend or do their act on behalf of the agency .',\n",
       "       'And then , in the 1907 Act , which is after , you know , the Enabling Act , it says all causes , civil or criminal , shall be proceeded with , held and determined by the courts of the state coming about , the successors of the district courts of the territory of Oklahoma , and the United States courts in the Indian territory .',\n",
       "       'You said that the EPA has plenty of tools available to it in that scenario to address any conflicts .',\n",
       "       \"And it was given , and not challenged , that they did n't hire men as cabin attendants .\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_sent_subset.sort_values('orientation').head(10).tokens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Let me ask you a question about the difference between you and the government .',\n",
       "       'Counsel , you spend a lot of time in your brief documenting that the purpose of these subpoenas was actually investigatory rather than legislative .',\n",
       "       '-- between -- what is the difference between that setup and the setup that Mr. Lessig says is required ?',\n",
       "       'Well , I -- I thought that in your brief , in your letter brief , you specifically rejected every other theory of -- of why this case was live .',\n",
       "       'May I ask you a question about this -- this theory of yours I saw nowhere aired below ?',\n",
       "       'I guess what struck me was that in many -- on many occasions you modified that test in your brief .',\n",
       "       'Mr. Citron , may I ask you a basic question of -- of what matters here ?',\n",
       "       \"Is there anything explicitly that terminated the reservation in the history that you 've recounted ?\",\n",
       "       \"It was n't raised in -- in the district court or in the court of appeals .\",\n",
       "       \"Ms. Ross , in -- in your brief , you say , you know , you 're --\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_sent_subset.sort_values('orientation').tail(10).tokens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
