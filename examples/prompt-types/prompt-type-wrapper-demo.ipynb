{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demos `PromptTypeWrapper`, a transformer that produces abstract representations of an utterance in terms of its phrasing and its rhetorical intent. \n",
    "\n",
    "The transformer, with some minor modifications, implements the methodology detailed in the [paper](http://www.cs.cornell.edu/~cristian/Asking_too_much.html), \n",
    "\n",
    "```\n",
    "Asking Too Much? The Rhetorical Role of Questions in Political Discourse \n",
    "Justine Zhang, Arthur Spirling, Cristian Danescu-Niculescu-Mizil\n",
    "Proceedings of EMNLP 2017\n",
    "```\n",
    "\n",
    "and by default analyzes _questions_ and their responses (though this can be modified on initialization). \n",
    "\n",
    "Under the surface, the transformer implements two key modules, `PhrasingMotifs` and `PromptTypes`, as well as a suite of preprocessing steps. For a more detailed description of each of these steps, and examples of calling the component modules separately, see [this notebook](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/prompt-types/prompt-type-demo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the corpus. We will examine a dataset of questions from question periods that take place in the British House of Commons (also detailed in the paper). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from convokit import Corpus\n",
    "from convokit import download\n",
    "from convokit.prompt_types import PromptTypeWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For expedience, we load pre-computed dependency parses, which should come with the data release (see [this notebook](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/text-processing/text_preprocessing_demo.ipynb) for a demonstration of how to get these parses for yourself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTION 1: DOWNLOAD CORPUS \n",
    "# UNCOMMENT THESE LINES TO DOWNLOAD CORPUS\n",
    "# DATA_DIR = '<YOUR DIRECTORY>'\n",
    "# ROOT_DIR = download('parliament-corpus', data_dir=DATA_DIR)\n",
    "\n",
    "# OPTION 2: READ PREVIOUSLY-DOWNLOADED CORPUS FROM DISK\n",
    "# UNCOMMENT THIS LINE AND REPLACE WITH THE DIRECTORY WHERE THE PARLIAMENT-CORPUS IS LOCATED\n",
    "# ROOT_DIR = '<YOUR DIRECTORY>'\n",
    "\n",
    "corpus = Corpus(ROOT_DIR)\n",
    "corpus.load_info('utterance',['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VERBOSITY = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting an example utterance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_utt_id = '1997-01-27a.4.0'\n",
    "utt = corpus.get_utterance(test_utt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Does my right hon Friend agree that last week 's statement about a replacement royal yacht has been widely welcomed ? Does he agree also that , ideally , Britannia should become the centrepiece of the millennium project in Portsmouth harbour , spanning Gosport and Portsmouth ? I am sure that that idea would prove very popular . As to plans for a new yacht , does my right hon Friend share my distaste for the Opposition 's tactics ? They had every opportunity to express their grudging and negative attitude during the past two years when the project was under discussion .\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a `PromptTypeWrapper` model, that will infer 8 types of questions (see docstring for other arguments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt = PromptTypeWrapper(n_types=8, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "counting frequent itemsets for 325339 sets\n",
      "\tfirst pass: counting itemsets up to and including 5 items large\n",
      "\tfirst pass: 10000/325339 sets processed\n",
      "\tfirst pass: 20000/325339 sets processed\n",
      "\tfirst pass: 30000/325339 sets processed\n",
      "\tfirst pass: 40000/325339 sets processed\n",
      "\tfirst pass: 50000/325339 sets processed\n",
      "\tfirst pass: 60000/325339 sets processed\n",
      "\tfirst pass: 70000/325339 sets processed\n",
      "\tfirst pass: 80000/325339 sets processed\n",
      "\tfirst pass: 90000/325339 sets processed\n",
      "\tfirst pass: 100000/325339 sets processed\n",
      "\tfirst pass: 110000/325339 sets processed\n",
      "\tfirst pass: 120000/325339 sets processed\n",
      "\tfirst pass: 130000/325339 sets processed\n",
      "\tfirst pass: 140000/325339 sets processed\n",
      "\tfirst pass: 150000/325339 sets processed\n",
      "\tfirst pass: 160000/325339 sets processed\n",
      "\tfirst pass: 170000/325339 sets processed\n",
      "\tfirst pass: 180000/325339 sets processed\n",
      "\tfirst pass: 190000/325339 sets processed\n",
      "\tfirst pass: 200000/325339 sets processed\n",
      "\tfirst pass: 210000/325339 sets processed\n",
      "\tfirst pass: 220000/325339 sets processed\n",
      "\tfirst pass: 230000/325339 sets processed\n",
      "\tfirst pass: 240000/325339 sets processed\n",
      "\tfirst pass: 250000/325339 sets processed\n",
      "\tfirst pass: 260000/325339 sets processed\n",
      "\tfirst pass: 270000/325339 sets processed\n",
      "\tfirst pass: 280000/325339 sets processed\n",
      "\tfirst pass: 290000/325339 sets processed\n",
      "\tfirst pass: 300000/325339 sets processed\n",
      "\tfirst pass: 310000/325339 sets processed\n",
      "\tfirst pass: 320000/325339 sets processed\n",
      "\tsecond pass: counting itemsets more than 5 items large\n",
      "\tsecond pass: checking 10486 sets for itemsets of length 6\n",
      "\tsecond pass: checked 10000/10486 sets for itemsets of length 6\n",
      "\tsecond pass: checking 538 sets for itemsets of length 7\n",
      "making itemset tree for 5797 itemsets\n",
      "deduplicating itemsets\n",
      "\tcounting itemset cooccurrences for 10000/318345 collections\n",
      "\tcounting itemset cooccurrences for 20000/318345 collections\n",
      "\tcounting itemset cooccurrences for 30000/318345 collections\n",
      "\tcounting itemset cooccurrences for 40000/318345 collections\n",
      "\tcounting itemset cooccurrences for 50000/318345 collections\n",
      "\tcounting itemset cooccurrences for 60000/318345 collections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcounting itemset cooccurrences for 70000/318345 collections\n",
      "\tcounting itemset cooccurrences for 80000/318345 collections\n",
      "\tcounting itemset cooccurrences for 90000/318345 collections\n",
      "\tcounting itemset cooccurrences for 100000/318345 collections\n",
      "\tcounting itemset cooccurrences for 110000/318345 collections\n",
      "\tcounting itemset cooccurrences for 120000/318345 collections\n",
      "\tcounting itemset cooccurrences for 130000/318345 collections\n",
      "\tcounting itemset cooccurrences for 140000/318345 collections\n",
      "\tcounting itemset cooccurrences for 150000/318345 collections\n",
      "\tcounting itemset cooccurrences for 160000/318345 collections\n",
      "\tcounting itemset cooccurrences for 170000/318345 collections\n",
      "\tcounting itemset cooccurrences for 180000/318345 collections\n",
      "\tcounting itemset cooccurrences for 190000/318345 collections\n",
      "\tcounting itemset cooccurrences for 200000/318345 collections\n",
      "\tcounting itemset cooccurrences for 210000/318345 collections\n",
      "\tcounting itemset cooccurrences for 220000/318345 collections\n",
      "\tcounting itemset cooccurrences for 230000/318345 collections\n",
      "\tcounting itemset cooccurrences for 240000/318345 collections\n",
      "\tcounting itemset cooccurrences for 250000/318345 collections\n",
      "\tcounting itemset cooccurrences for 260000/318345 collections\n",
      "\tcounting itemset cooccurrences for 270000/318345 collections\n",
      "\tcounting itemset cooccurrences for 280000/318345 collections\n",
      "\tcounting itemset cooccurrences for 290000/318345 collections\n",
      "\tcounting itemset cooccurrences for 300000/318345 collections\n",
      "\tcounting itemset cooccurrences for 310000/318345 collections\n",
      "\tfinding supersets\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "fitting 195441 input pairs\n",
      "fitting ref tfidf model\n",
      "fitting prompt tfidf model\n",
      "fitting svd model\n",
      "fitting 8 prompt types\n"
     ]
    }
   ],
   "source": [
    "pt.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output. Note that this should produce the same output as calling the component transformers separately, as detailed in [this notebook](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/prompt-types/prompt-type-wrapper-demo.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "top prompt:\n",
      "                                     0         1         2         3  \\\n",
      "made_*                        0.642670  1.260725  1.112202  1.119975   \n",
      "made_*__made_in               0.686119  1.166733  1.092458  1.101651   \n",
      "in>*__tell_*                  0.686683  1.330053  1.175609  1.265570   \n",
      "made_*__made_to               0.697633  1.386197  1.226340  1.180139   \n",
      "made_*__made_what             0.698968  1.247663  1.124691  0.959685   \n",
      "happen_*__happen_will         0.701071  1.231780  1.202306  1.119589   \n",
      "made_*__made_been             0.709813  1.263380  1.122509  1.178115   \n",
      "made_*__what>*                0.716440  1.247333  1.148910  0.997612   \n",
      "give_*__give_on               0.720038  1.212984  1.041744  1.057502   \n",
      "include_*                     0.720358  1.198579  1.072563  1.225554   \n",
      "made_*__made_been__made_what  0.722511  1.225216  1.105467  1.051967   \n",
      "made_*__made_has              0.725824  1.304950  1.122941  1.108813   \n",
      "give_*                        0.728294  1.168802  0.898816  1.139529   \n",
      "made_*__made_has__made_in     0.728905  1.262225  1.097236  1.069485   \n",
      "give_*__give_will             0.736490  1.204622  0.886754  1.193561   \n",
      "\n",
      "                                     4         5         6         7  type_id  \n",
      "made_*                        1.109806  1.090654  1.074203  1.238417      0.0  \n",
      "made_*__made_in               1.134036  1.106717  1.041628  1.283886      0.0  \n",
      "in>*__tell_*                  0.999056  0.861247  1.113234  0.966570      0.0  \n",
      "made_*__made_to               1.229341  1.124440  1.141026  1.202450      0.0  \n",
      "made_*__made_what             1.231582  1.120818  1.135028  1.338315      0.0  \n",
      "happen_*__happen_will         1.065650  0.875300  1.150445  1.086889      0.0  \n",
      "made_*__made_been             1.196155  1.156079  1.112907  1.262480      0.0  \n",
      "made_*__what>*                1.248624  1.164274  1.135320  1.346459      0.0  \n",
      "give_*__give_on               1.040212  0.867584  1.116197  1.148288      0.0  \n",
      "include_*                     0.972105  1.002314  0.975734  1.058022      0.0  \n",
      "made_*__made_been__made_what  1.248038  1.172963  1.131069  1.321350      0.0  \n",
      "made_*__made_has              1.244116  1.147545  1.177114  1.290685      0.0  \n",
      "give_*                        0.898485  0.729399  0.896333  1.107519      0.0  \n",
      "made_*__made_has__made_in     1.249971  1.081304  1.172150  1.250931      0.0  \n",
      "give_*__give_will             0.906276  0.788050  0.864556  1.123579      0.0  \n",
      "top response:\n",
      "                       0         1         2         3         4         5  \\\n",
      "am_at           0.754168  1.218312  0.935100  1.236106  1.094640  1.032641   \n",
      "known_*         0.762373  1.270855  1.226598  1.241985  1.086090  1.041787   \n",
      "make_shall      0.796174  0.950901  0.872780  1.126165  0.851466  0.902901   \n",
      "can_*           0.796596  1.082337  1.108318  0.978166  1.077126  1.001777   \n",
      "was_made        0.798567  1.176747  1.185672  1.194271  0.949985  0.924359   \n",
      "assure_have     0.799604  0.968214  0.945763  0.992954  1.045496  1.083873   \n",
      "have_made       0.801065  1.061900  1.044006  1.211930  0.842938  1.052175   \n",
      "place_*         0.804806  1.156076  1.049486  1.121062  1.105140  1.041889   \n",
      "considering_is  0.817474  1.157802  1.004836  1.216603  1.033228  1.100037   \n",
      "give_can        0.817774  1.221705  1.036614  1.127346  1.085148  0.845947   \n",
      "offered_have    0.818643  1.258053  1.192961  1.247103  1.078759  1.077084   \n",
      "announce_*      0.828690  1.164386  1.065661  1.058407  1.165244  1.050387   \n",
      "check_*         0.829329  1.309865  1.139447  1.188038  1.210644  1.035843   \n",
      "write_shall     0.829789  1.271439  1.159690  1.183101  1.211245  1.113749   \n",
      "write_with      0.830393  1.273412  1.158927  1.178765  1.212505  1.108228   \n",
      "\n",
      "                       6         7  type_id  \n",
      "am_at           1.057299  1.190314      0.0  \n",
      "known_*         1.149278  1.110620      0.0  \n",
      "make_shall      0.893270  1.166567      0.0  \n",
      "can_*           1.056306  1.191984      0.0  \n",
      "was_made        1.142506  0.972187      0.0  \n",
      "assure_have     0.912426  1.287851      0.0  \n",
      "have_made       0.916446  1.169841      0.0  \n",
      "place_*         1.042189  1.153683      0.0  \n",
      "considering_is  0.840997  1.248955      0.0  \n",
      "give_can        1.063921  1.142911      0.0  \n",
      "offered_have    1.072029  1.071767      0.0  \n",
      "announce_*      1.128076  1.305602      0.0  \n",
      "check_*         1.155101  1.091883      0.0  \n",
      "write_shall     1.166478  1.120017      0.0  \n",
      "write_with      1.168921  1.117963      0.0  \n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "top prompt:\n",
      "                                                0         1         2  \\\n",
      "agree_*__agree_is                        1.178031  0.392994  1.060446   \n",
      "agree_*__agree_be__does>*                1.135692  0.400345  1.017279   \n",
      "agree_*__agree_is__does>*                1.175818  0.400844  1.064866   \n",
      "agree_*__agree_be                        1.130732  0.401616  1.019973   \n",
      "agree_*__agree_have                      1.150848  0.443389  1.058488   \n",
      "agree_*__agree_are                       1.190365  0.449033  1.090853   \n",
      "agree_*__agree_does__agree_have__does>*  1.135804  0.457290  1.089983   \n",
      "agree_*__agree_are__agree_does__does>*   1.191144  0.460577  1.096827   \n",
      "agree_*__agree_also                      1.176007  0.469945  1.133404   \n",
      "continue_*__will>*                       1.144928  0.474175  1.038749   \n",
      "agree_*__as>*                            1.124752  0.501247  0.949284   \n",
      "agree_*__agree_does__as>*                1.147453  0.507481  0.971820   \n",
      "agree_*__agree_welcome                   1.203914  0.508741  1.044801   \n",
      "is_*__is_agree                           1.205125  0.510086  1.110060   \n",
      "learned_*__learned_agree                 1.150620  0.510949  1.114529   \n",
      "\n",
      "                                                3         4         5  \\\n",
      "agree_*__agree_is                        1.118347  0.855209  1.245478   \n",
      "agree_*__agree_be__does>*                1.131241  0.792990  1.213395   \n",
      "agree_*__agree_is__does>*                1.112551  0.863416  1.251924   \n",
      "agree_*__agree_be                        1.136800  0.783320  1.204353   \n",
      "agree_*__agree_have                      1.128842  0.857956  1.246168   \n",
      "agree_*__agree_are                       1.160460  0.853937  1.257627   \n",
      "agree_*__agree_does__agree_have__does>*  1.115280  0.841571  1.235343   \n",
      "agree_*__agree_are__agree_does__does>*   1.157171  0.862814  1.263466   \n",
      "agree_*__agree_also                      1.174203  0.886887  1.278550   \n",
      "continue_*__will>*                       0.984086  0.959959  1.204275   \n",
      "agree_*__as>*                            1.138565  0.797229  1.184821   \n",
      "agree_*__agree_does__as>*                1.164712  0.828512  1.214503   \n",
      "agree_*__agree_welcome                   1.115074  0.861948  1.146991   \n",
      "is_*__is_agree                           1.200722  0.844801  1.242438   \n",
      "learned_*__learned_agree                 1.205899  0.846344  1.288598   \n",
      "\n",
      "                                                6         7  type_id  \n",
      "agree_*__agree_is                        0.957048  1.149282      1.0  \n",
      "agree_*__agree_be__does>*                0.888559  1.157708      1.0  \n",
      "agree_*__agree_is__does>*                0.958897  1.152021      1.0  \n",
      "agree_*__agree_be                        0.881920  1.156517      1.0  \n",
      "agree_*__agree_have                      0.958250  1.169463      1.0  \n",
      "agree_*__agree_are                       0.944175  1.150599      1.0  \n",
      "agree_*__agree_does__agree_have__does>*  0.959817  1.151314      1.0  \n",
      "agree_*__agree_are__agree_does__does>*   0.948823  1.148104      1.0  \n",
      "agree_*__agree_also                      1.029875  1.136467      1.0  \n",
      "continue_*__will>*                       0.972601  1.214005      1.0  \n",
      "agree_*__as>*                            0.851265  1.206571      1.0  \n",
      "agree_*__agree_does__as>*                0.869202  1.206230      1.0  \n",
      "agree_*__agree_welcome                   0.981365  1.091862      1.0  \n",
      "is_*__is_agree                           0.927002  1.124411      1.0  \n",
      "learned_*__learned_agree                 0.893007  1.134564      1.0  \n",
      "top response:\n",
      "                             0         1         2         3         4  \\\n",
      "agree_certainly       1.172600  0.465506  1.069451  1.099853  0.948805   \n",
      "agree_is              1.166624  0.472614  1.069428  1.093611  0.947803   \n",
      "agree_however         1.164143  0.473389  1.074121  1.115208  0.929423   \n",
      "agree_will            1.173610  0.479482  1.040547  1.119927  0.944613   \n",
      "agree_also            1.186571  0.479957  1.076302  1.094734  0.942869   \n",
      "agree_absolutely      1.186106  0.480638  1.060317  1.066145  0.983891   \n",
      "agree_wholeheartedly  1.176771  0.481028  1.090431  1.087757  0.959604   \n",
      "is_also               1.187847  0.481143  1.050677  0.999050  0.867820   \n",
      "agree_strongly        1.174496  0.485545  1.086276  1.061606  0.976277   \n",
      "agree_completely      1.178798  0.485695  1.086973  1.074517  0.973782   \n",
      "agree_be              1.157274  0.486000  1.077425  1.102518  0.940736   \n",
      "is_vital              1.145542  0.486760  1.006241  0.948051  0.924983   \n",
      "is_reduce             1.104239  0.487099  1.052885  1.132830  0.747489   \n",
      "agree_are             1.170594  0.487802  1.078409  1.071283  0.960251   \n",
      "agree_totally         1.174853  0.488112  1.101322  1.113340  0.921742   \n",
      "\n",
      "                             5         6         7  type_id  \n",
      "agree_certainly       1.309079  0.975690  1.206101      1.0  \n",
      "agree_is              1.307342  0.989236  1.209806      1.0  \n",
      "agree_however         1.302398  0.999549  1.198431      1.0  \n",
      "agree_will            1.307097  1.005520  1.214075      1.0  \n",
      "agree_also            1.310332  0.994407  1.199438      1.0  \n",
      "agree_absolutely      1.310408  0.987268  1.224410      1.0  \n",
      "agree_wholeheartedly  1.295036  1.021919  1.197020      1.0  \n",
      "is_also               1.105690  0.991532  1.118194      1.0  \n",
      "agree_strongly        1.311594  1.025479  1.223978      1.0  \n",
      "agree_completely      1.314119  1.020939  1.213598      1.0  \n",
      "agree_be              1.304915  0.997933  1.207461      1.0  \n",
      "is_vital              1.149789  0.974998  1.207240      1.0  \n",
      "is_reduce             1.167290  0.895301  1.104156      1.0  \n",
      "agree_are             1.297376  1.011452  1.203730      1.0  \n",
      "agree_totally         1.290903  1.027282  1.161894      1.0  \n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "top prompt:\n",
      "                                    0         1         2         3         4  \\\n",
      "agree_*__agree_will__will>*  1.065945  0.933009  0.499633  1.084009  1.012219   \n",
      "agree_*__agree_will          1.041571  0.946486  0.499767  1.086585  0.983468   \n",
      "agree_*__will>*              1.089274  0.875183  0.517089  1.098418  0.990540   \n",
      "meet_*                       1.110268  1.007127  0.549192  1.028934  1.033697   \n",
      "agree_*__agree_meet          1.101323  1.033288  0.561753  1.107145  1.082005   \n",
      "agree_*__agree_meet__will>*  1.131027  1.076302  0.562333  1.085705  1.148063   \n",
      "undertake_*                  0.997951  1.018223  0.576309  1.053467  1.037190   \n",
      "meet_*__meet_will            1.120822  0.983597  0.582086  1.039654  1.020057   \n",
      "raise_*__raise_will          1.030311  0.992279  0.582527  1.093984  1.057581   \n",
      "press_*__press_may           1.099238  1.103950  0.584946  1.118133  1.018230   \n",
      "bring_*__bring_will__will>*  1.013467  1.069336  0.590264  1.081374  1.102187   \n",
      "ensure_*__will>*             1.062313  0.776609  0.592105  1.017104  1.003323   \n",
      "ensure_*                     1.032968  0.789210  0.597887  0.977866  0.982472   \n",
      "meet_*__will>*               1.117968  0.999152  0.600541  1.039263  1.032646   \n",
      "ensure_*__ensure_will        1.033369  0.758211  0.605703  1.002250  0.956445   \n",
      "\n",
      "                                    5         6         7  type_id  \n",
      "agree_*__agree_will__will>*  1.000869  0.848304  1.261513      2.0  \n",
      "agree_*__agree_will          0.956083  0.848897  1.253908      2.0  \n",
      "agree_*__will>*              1.025834  0.847072  1.252733      2.0  \n",
      "meet_*                       0.918049  0.876785  1.244351      2.0  \n",
      "agree_*__agree_meet          1.040578  0.928635  1.292762      2.0  \n",
      "agree_*__agree_meet__will>*  1.067604  0.990012  1.291691      2.0  \n",
      "undertake_*                  1.010836  0.801511  1.246797      2.0  \n",
      "meet_*__meet_will            0.912081  0.876618  1.225844      2.0  \n",
      "raise_*__raise_will          1.094661  0.889936  1.301384      2.0  \n",
      "press_*__press_may           0.876615  0.878413  1.222558      2.0  \n",
      "bring_*__bring_will__will>*  1.036312  0.912358  1.276315      2.0  \n",
      "ensure_*__will>*             1.129365  0.763546  1.308970      2.0  \n",
      "ensure_*                     1.086783  0.729252  1.300186      2.0  \n",
      "meet_*__will>*               0.927597  0.908010  1.219014      2.0  \n",
      "ensure_*__ensure_will        1.084999  0.713192  1.294998      2.0  \n",
      "top response:\n",
      "                       0         1         2         3         4         5  \\\n",
      "am_always       1.141625  0.959928  0.586058  1.202951  0.978357  0.996299   \n",
      "am_aware        0.917523  1.134168  0.614082  1.168166  1.044951  1.011632   \n",
      "was_aware       1.089144  1.156734  0.635324  1.263031  1.123436  1.108677   \n",
      "want_obviously  1.181632  1.007112  0.642615  1.071297  1.118635  1.047020   \n",
      "know_been       1.039754  0.873892  0.651870  1.102556  1.004476  1.022890   \n",
      "know_takes      1.066778  0.844689  0.657154  0.947291  1.059950  1.096251   \n",
      "am_interested   1.147764  1.204840  0.676728  1.260703  1.029487  0.952051   \n",
      "get_back        1.164913  1.143315  0.676827  1.201392  1.216430  1.140033   \n",
      "suspect_is      1.082123  1.044955  0.678317  1.204624  0.959086  0.859566   \n",
      "be_happy        0.976479  0.852003  0.689113  1.106753  0.806586  0.855737   \n",
      "like>*          1.199913  0.721725  0.698652  1.064717  1.011368  1.102202   \n",
      "know_will       0.995451  0.791780  0.704248  1.061125  0.821602  0.941124   \n",
      "see_is          1.134095  1.014071  0.704949  1.197196  0.897167  0.786096   \n",
      "is_clearly      1.126972  0.755034  0.706200  1.096818  0.892752  1.065010   \n",
      "am_not          0.940934  1.081212  0.706260  1.285820  0.907726  0.968193   \n",
      "\n",
      "                       6         7  type_id  \n",
      "am_always       0.790126  1.210981      2.0  \n",
      "am_aware        0.801923  1.248339      2.0  \n",
      "was_aware       0.990186  1.207972      2.0  \n",
      "want_obviously  0.796427  1.263513      2.0  \n",
      "know_been       0.890026  1.218825      2.0  \n",
      "know_takes      0.856168  1.294005      2.0  \n",
      "am_interested   1.012655  1.105208      2.0  \n",
      "get_back        1.084493  1.237411      2.0  \n",
      "suspect_is      1.010869  1.088968      2.0  \n",
      "be_happy        0.787719  1.174184      2.0  \n",
      "like>*          0.927534  1.254203      2.0  \n",
      "know_will       0.802742  1.133070      2.0  \n",
      "see_is          0.998480  1.031511      2.0  \n",
      "is_clearly      0.807707  1.233621      2.0  \n",
      "am_not          0.879971  1.086447      2.0  \n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "top prompt:\n",
      "                                     0         1         2         3  \\\n",
      "doing_*__what>*               1.184430  1.160051  1.178999  0.488050   \n",
      "doing_*                       1.191700  1.142959  1.177319  0.501816   \n",
      "taking_*__taking_is__what>*   1.123601  1.159411  1.190865  0.510735   \n",
      "doing_*__doing_is__what>*     1.191761  1.212333  1.201727  0.529937   \n",
      "take_*__take_what             1.146526  1.089185  1.011824  0.533417   \n",
      "will>*__work_*__work_with     1.050524  1.017746  0.970711  0.534472   \n",
      "taking_*__taking_are          1.084673  1.191355  1.218779  0.537272   \n",
      "taking_*                      1.130205  1.188690  1.230882  0.538174   \n",
      "do_*__do_can__do_what         1.180091  1.113888  1.030961  0.540809   \n",
      "do_*__do_what                 1.165401  1.098882  1.067617  0.541254   \n",
      "doing_*__doing_is             1.200928  1.207163  1.219990  0.542058   \n",
      "taking_*__what>*              1.081665  1.195913  1.223669  0.544559   \n",
      "doing_*__doing_are__what>*    1.168104  1.094558  1.152772  0.551494   \n",
      "work_*__work_will__work_with  1.087645  1.027759  0.949363  0.555932   \n",
      "work_*__work_with             1.107101  0.976240  0.939908  0.557589   \n",
      "\n",
      "                                     4         5         6         7  type_id  \n",
      "doing_*__what>*               1.386599  1.186412  1.284258  1.287443      3.0  \n",
      "doing_*                       1.350304  1.173648  1.268916  1.264836      3.0  \n",
      "taking_*__taking_is__what>*   1.414406  1.205223  1.244082  1.319723      3.0  \n",
      "doing_*__doing_is__what>*     1.425453  1.211172  1.311345  1.293667      3.0  \n",
      "take_*__take_what             1.313574  1.184682  1.187420  1.327100      3.0  \n",
      "will>*__work_*__work_with     1.275169  1.171770  1.118736  1.365324      3.0  \n",
      "taking_*__taking_are          1.412307  1.216108  1.236338  1.340700      3.0  \n",
      "taking_*                      1.427114  1.233252  1.253872  1.327655      3.0  \n",
      "do_*__do_can__do_what         1.368097  1.110968  1.243936  1.312068      3.0  \n",
      "do_*__do_what                 1.302473  1.066484  1.242200  1.240333      3.0  \n",
      "doing_*__doing_is             1.401014  1.200115  1.299430  1.270280      3.0  \n",
      "taking_*__what>*              1.423648  1.222843  1.252178  1.342849      3.0  \n",
      "doing_*__doing_are__what>*    1.312144  1.144682  1.235490  1.256895      3.0  \n",
      "work_*__work_will__work_with  1.296737  1.195333  1.141504  1.370647      3.0  \n",
      "work_*__work_with             1.276967  1.205244  1.119050  1.372105      3.0  \n",
      "top response:\n",
      "                       0         1         2         3         4         5  \\\n",
      "is_working      1.121276  0.977121  1.152816  0.641780  1.215306  1.164396   \n",
      "through>*       1.167658  1.054884  1.241109  0.644175  1.376545  1.277029   \n",
      "ensuring_is     1.190223  0.954022  1.087456  0.646023  1.232338  1.165198   \n",
      "supporting_are  1.213406  1.175711  1.244784  0.653694  1.362103  1.186255   \n",
      "working_on      1.133991  1.306494  1.224075  0.666115  1.389232  1.233873   \n",
      "ensuring_*      1.171578  0.924811  1.122618  0.667330  1.186674  1.112692   \n",
      "supporting_*    1.219621  1.193960  1.257770  0.667436  1.387225  1.207561   \n",
      "ensure_to       1.060670  0.860925  0.999262  0.671606  1.162069  1.115536   \n",
      "working_are     1.136252  1.310082  1.228715  0.672006  1.386959  1.229363   \n",
      "working_with    1.136227  1.312572  1.227211  0.674281  1.388676  1.230104   \n",
      "working_*       1.138188  1.310363  1.229160  0.674613  1.388104  1.231210   \n",
      "working_hard    1.139996  1.311699  1.231134  0.674654  1.390631  1.233906   \n",
      "working_also    1.139920  1.310157  1.227036  0.675715  1.388369  1.233105   \n",
      "working_make    1.137645  1.313886  1.222169  0.676573  1.393486  1.233362   \n",
      "working_in      1.144143  1.304679  1.226546  0.678347  1.382191  1.230175   \n",
      "\n",
      "                       6         7  type_id  \n",
      "is_working      1.204946  1.272095      3.0  \n",
      "through>*       1.280213  1.319970      3.0  \n",
      "ensuring_is     1.111981  1.236440      3.0  \n",
      "supporting_are  1.289802  1.236259      3.0  \n",
      "working_on      1.278601  1.280007      3.0  \n",
      "ensuring_*      1.151376  1.222170      3.0  \n",
      "supporting_*    1.317493  1.247463      3.0  \n",
      "ensure_to       1.100086  1.283869      3.0  \n",
      "working_are     1.279944  1.273441      3.0  \n",
      "working_with    1.279104  1.274829      3.0  \n",
      "working_*       1.280503  1.273328      3.0  \n",
      "working_hard    1.281484  1.270713      3.0  \n",
      "working_also    1.280198  1.273076      3.0  \n",
      "working_make    1.282217  1.277147      3.0  \n",
      "working_in      1.277246  1.268103      3.0  \n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "top prompt:\n",
      "                                         0         1         2         3  \\\n",
      "accept_*__accept_is               1.079235  0.681049  1.059769  1.277550   \n",
      "accept_*__accept_will             1.101589  0.789447  1.052373  1.341621   \n",
      "accept_*__accept_does__accept_is  1.079983  0.681629  1.079337  1.280061   \n",
      "accept_*                          1.106794  0.746544  1.082207  1.325616   \n",
      "be_*__be_not                      0.973315  0.802152  0.984162  1.315738   \n",
      "accept_*__accept_is__does>*       1.062281  0.703920  1.108721  1.280577   \n",
      "accept_*__accept_does             1.111590  0.740533  1.105143  1.317692   \n",
      "accept_*__will>*                  1.109230  0.744342  1.032369  1.340217   \n",
      "be_*                              0.896092  0.891208  0.935270  1.291994   \n",
      "be_*__be_would                    0.968819  0.828916  0.918996  1.327139   \n",
      "does>*__recognise_*               1.125926  0.802221  0.989390  1.318611   \n",
      "accept_*__does>*                  1.119327  0.732728  1.118851  1.319119   \n",
      "recognise_*__recognise_does       1.140345  0.754539  0.999911  1.311176   \n",
      "confirm_*__confirm_have__will>*   1.071553  0.851461  0.995091  1.282852   \n",
      "be_*__be_not__be_would            0.980373  0.832898  0.974302  1.317864   \n",
      "\n",
      "                                         4         5         6         7  \\\n",
      "accept_*__accept_is               0.505971  1.051125  0.832409  0.943473   \n",
      "accept_*__accept_will             0.509847  0.948455  0.847565  0.831503   \n",
      "accept_*__accept_does__accept_is  0.514329  1.066350  0.864905  0.946460   \n",
      "accept_*                          0.521204  1.004953  0.849318  0.874334   \n",
      "be_*__be_not                      0.526868  0.971646  0.699766  0.981070   \n",
      "accept_*__accept_is__does>*       0.535162  1.063187  0.891956  0.941848   \n",
      "accept_*__accept_does             0.540983  1.030566  0.860792  0.880102   \n",
      "accept_*__will>*                  0.544735  0.974776  0.801110  0.869858   \n",
      "be_*                              0.545127  0.858343  0.712597  1.020985   \n",
      "be_*__be_would                    0.546880  0.948586  0.675103  1.009259   \n",
      "does>*__recognise_*               0.556083  1.031753  0.754055  0.993918   \n",
      "accept_*__does>*                  0.558315  1.049014  0.878689  0.879332   \n",
      "recognise_*__recognise_does       0.562445  1.011495  0.796511  0.965115   \n",
      "confirm_*__confirm_have__will>*   0.568952  0.821783  0.958812  0.905298   \n",
      "be_*__be_not__be_would            0.569661  0.976666  0.674426  0.996337   \n",
      "\n",
      "                                  type_id  \n",
      "accept_*__accept_is                   4.0  \n",
      "accept_*__accept_will                 4.0  \n",
      "accept_*__accept_does__accept_is      4.0  \n",
      "accept_*                              4.0  \n",
      "be_*__be_not                          4.0  \n",
      "accept_*__accept_is__does>*           4.0  \n",
      "accept_*__accept_does                 4.0  \n",
      "accept_*__will>*                      4.0  \n",
      "be_*                                  4.0  \n",
      "be_*__be_would                        4.0  \n",
      "does>*__recognise_*                   4.0  \n",
      "accept_*__does>*                      4.0  \n",
      "recognise_*__recognise_does           4.0  \n",
      "confirm_*__confirm_have__will>*       4.0  \n",
      "be_*__be_not__be_would                4.0  \n",
      "top response:\n",
      "                        0         1         2         3         4         5  \\\n",
      "realise_*        1.040393  0.894181  1.038655  1.331841  0.500252  0.890670   \n",
      "therefore>*      1.061499  0.893750  1.104857  1.354618  0.513607  0.866602   \n",
      "realise_is       1.063878  0.817943  1.038343  1.286916  0.524440  0.957527   \n",
      "is_not           1.087985  0.764481  1.031469  1.204602  0.581503  0.825972   \n",
      "be_right         0.970716  0.880698  0.999525  1.215149  0.589751  0.828816   \n",
      "believe_however  1.044246  0.737620  0.950810  1.203838  0.590879  0.912205   \n",
      "be_were          1.043752  0.677415  0.922338  1.210474  0.591804  0.914242   \n",
      "be_might         1.089247  0.672569  0.896184  1.170629  0.592638  0.896910   \n",
      "knows_is         0.974751  1.025386  1.076116  1.348779  0.594608  0.870005   \n",
      "be_would         1.026629  0.691166  0.878918  1.176968  0.595954  0.876801   \n",
      "be_however       0.989855  0.744732  0.832940  1.200455  0.598274  0.880731   \n",
      "remind_is        1.084782  0.945154  0.952783  1.333410  0.598299  0.966751   \n",
      "be_still         1.085797  0.750013  1.051154  1.290092  0.598332  1.019586   \n",
      "be_better        1.068343  0.631089  1.001237  1.171130  0.601310  0.943643   \n",
      "be_indeed        1.028892  0.680410  0.977496  1.147426  0.604000  0.963538   \n",
      "\n",
      "                        6         7  type_id  \n",
      "realise_*        0.825493  0.874845      4.0  \n",
      "therefore>*      0.889318  0.797758      4.0  \n",
      "realise_is       0.874275  0.905790      4.0  \n",
      "is_not           0.904295  0.921863      4.0  \n",
      "be_right         0.821476  1.009707      4.0  \n",
      "believe_however  0.780248  1.036202      4.0  \n",
      "be_were          0.767221  0.997343      4.0  \n",
      "be_might         0.767016  1.008989      4.0  \n",
      "knows_is         0.865941  0.839134      4.0  \n",
      "be_would         0.756260  1.055530      4.0  \n",
      "be_however       0.702222  1.087620      4.0  \n",
      "remind_is        0.852056  0.928393      4.0  \n",
      "be_still         0.844965  1.015357      4.0  \n",
      "be_better        0.847942  0.985411      4.0  \n",
      "be_indeed        0.719609  1.063146      4.0  \n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "top prompt:\n",
      "                                           0         1         2         3  \\\n",
      "say_*                               0.844813  1.290439  1.083605  1.191817   \n",
      "mean_*                              0.985430  1.168778  1.121422  1.198446   \n",
      "have_*                              0.929319  1.095207  0.850475  1.122292   \n",
      "mean_*__mean_does                   0.950284  1.214787  1.148634  1.238836   \n",
      "given>*                             0.995741  1.150381  0.824746  0.945626   \n",
      "make_*__make_what                   1.023998  1.072863  1.022946  1.198281   \n",
      "have_*__have_for__have_what         1.029358  1.286793  0.961728  1.136038   \n",
      "explain_*__explain_can__explain_is  1.079210  1.201702  1.088747  1.185033   \n",
      "said_*                              1.049226  1.201425  0.868288  1.094048   \n",
      "reassure_*__reassure_will           0.960865  1.008478  0.958209  1.058624   \n",
      "go_*                                1.070021  1.072962  0.949843  1.255850   \n",
      "if>*__is_*__is_what                 0.961019  1.263140  1.070935  1.217834   \n",
      "say_*__say_to                       1.059011  1.382067  1.116314  1.173534   \n",
      "reassure_*                          0.949283  0.999510  0.963429  0.938674   \n",
      "confirm_*__confirm_be               0.961552  1.040181  1.007852  1.213784   \n",
      "\n",
      "                                           4         5         6         7  \\\n",
      "say_*                               1.002093  0.597033  1.110283  0.964362   \n",
      "mean_*                              0.811768  0.608016  1.103757  0.862028   \n",
      "have_*                              0.828581  0.637613  0.840603  0.984206   \n",
      "mean_*__mean_does                   0.851205  0.650016  1.139283  0.868331   \n",
      "given>*                             1.049835  0.666502  0.995093  1.132441   \n",
      "make_*__make_what                   0.790423  0.674999  1.041058  0.894653   \n",
      "have_*__have_for__have_what         1.100350  0.680352  1.140965  1.089099   \n",
      "explain_*__explain_can__explain_is  0.882658  0.680379  1.138268  0.818482   \n",
      "said_*                              0.971472  0.682635  1.069825  1.024768   \n",
      "reassure_*__reassure_will           0.876908  0.686124  0.978712  1.116670   \n",
      "go_*                                0.723844  0.686258  0.930190  0.938877   \n",
      "if>*__is_*__is_what                 0.989889  0.687115  1.114823  0.958138   \n",
      "say_*__say_to                       1.162316  0.690230  1.220361  0.969999   \n",
      "reassure_*                          0.928771  0.695868  1.000904  1.135078   \n",
      "confirm_*__confirm_be               0.747302  0.696999  0.906389  1.043056   \n",
      "\n",
      "                                    type_id  \n",
      "say_*                                   5.0  \n",
      "mean_*                                  5.0  \n",
      "have_*                                  5.0  \n",
      "mean_*__mean_does                       5.0  \n",
      "given>*                                 5.0  \n",
      "make_*__make_what                       5.0  \n",
      "have_*__have_for__have_what             5.0  \n",
      "explain_*__explain_can__explain_is      5.0  \n",
      "said_*                                  5.0  \n",
      "reassure_*__reassure_will               5.0  \n",
      "go_*                                    5.0  \n",
      "if>*__is_*__is_what                     5.0  \n",
      "say_*__say_to                           5.0  \n",
      "reassure_*                              5.0  \n",
      "confirm_*__confirm_be                   5.0  \n",
      "top response:\n",
      "                     0         1         2         3         4         5  \\\n",
      "said_in       1.064670  1.223581  1.110079  1.221658  0.911053  0.598763   \n",
      "said_to       1.035921  1.262372  1.109663  1.197845  0.998079  0.602709   \n",
      "said_as       1.074941  1.191756  1.054068  1.191375  0.957537  0.625072   \n",
      "secondly>*    1.149565  1.193767  1.165417  1.147899  0.986640  0.641707   \n",
      "first>*       1.157380  1.212116  1.092610  1.109398  1.043735  0.643525   \n",
      "said_*        1.055139  1.179687  1.125506  1.254445  0.861226  0.643948   \n",
      "is_say        1.057567  1.062097  0.999974  1.135578  0.878154  0.652528   \n",
      "said_was      1.071921  1.213045  1.140768  1.236422  0.898741  0.654307   \n",
      "said_have     1.029431  1.200393  1.120920  1.243684  0.889604  0.659606   \n",
      "said_already  1.026182  1.209187  1.093169  1.253655  0.898125  0.661878   \n",
      "on>*          0.901745  1.079564  1.053403  1.240890  0.747147  0.662804   \n",
      "having>*      1.072542  1.044920  0.947258  1.181824  0.801248  0.663140   \n",
      "say_in        1.051628  1.416507  1.113449  1.165897  1.172278  0.664834   \n",
      "was_about     1.002523  1.270709  1.061779  1.096741  1.042059  0.667379   \n",
      "expect_do     0.953428  1.221590  1.001668  1.298919  0.865200  0.670890   \n",
      "\n",
      "                     6         7  type_id  \n",
      "said_in       1.149801  0.877360      5.0  \n",
      "said_to       1.149530  0.955832      5.0  \n",
      "said_as       1.131126  0.983568      5.0  \n",
      "secondly>*    1.218657  0.833936      5.0  \n",
      "first>*       1.211625  0.915545      5.0  \n",
      "said_*        1.137388  0.883522      5.0  \n",
      "is_say        1.070699  0.937304      5.0  \n",
      "said_was      1.151678  0.853728      5.0  \n",
      "said_have     1.133607  0.938168      5.0  \n",
      "said_already  1.132186  0.947027      5.0  \n",
      "on>*          0.987374  0.885210      5.0  \n",
      "having>*      0.956259  0.924430      5.0  \n",
      "say_in        1.244474  1.005729      5.0  \n",
      "was_about     1.138448  0.994684      5.0  \n",
      "expect_do     1.011991  0.951491      5.0  \n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "top prompt:\n",
      "                                          0         1         2         3  \\\n",
      "learned_*__will_*                  1.026398  0.839139  0.902978  1.299991   \n",
      "learned_*__will>*                  1.020684  0.850338  0.886134  1.296791   \n",
      "draw_*__will>*                     1.015710  0.939029  0.905083  1.171678   \n",
      "bear_*__bear_in__in>*              1.070145  0.980469  0.952697  1.224160   \n",
      "draw_*__draw_will                  1.030459  0.903381  0.907901  1.177064   \n",
      "will_*                             0.989236  0.832488  0.842190  1.312641   \n",
      "convey_*__convey_to                1.075775  1.013232  0.958067  1.231916   \n",
      "convey_*__convey_to__convey_will   1.100475  0.984957  1.022428  1.216595   \n",
      "will>*__will_*                     0.988328  0.863603  0.821040  1.321337   \n",
      "does_*__learned_*__learned_accept  1.093811  0.871545  0.995997  1.324486   \n",
      "try_*__try_will                    1.125981  0.815190  0.908259  1.234938   \n",
      "discuss_*__discuss_meets           1.029269  0.944456  0.948817  1.254969   \n",
      "consider_*__consider_will__if>*    1.051974  1.114890  0.926378  1.231515   \n",
      "consider_*__when>*                 1.068421  1.159172  0.886236  1.286190   \n",
      "consider_*__if>*                   1.056293  1.105007  0.936454  1.249197   \n",
      "\n",
      "                                          4         5         6         7  \\\n",
      "learned_*__will_*                  0.810461  1.164459  0.543140  1.165105   \n",
      "learned_*__will>*                  0.834257  1.163351  0.546050  1.172838   \n",
      "draw_*__will>*                     0.884846  1.059662  0.552131  1.143805   \n",
      "bear_*__bear_in__in>*              0.988823  1.167938  0.557521  1.221523   \n",
      "draw_*__draw_will                  0.882725  1.079581  0.563771  1.151367   \n",
      "will_*                             0.733349  1.107964  0.569536  1.135381   \n",
      "convey_*__convey_to                0.988978  1.092174  0.572072  1.172205   \n",
      "convey_*__convey_to__convey_will   0.989714  1.134072  0.595886  1.156473   \n",
      "will>*__will_*                     0.779188  1.133314  0.596799  1.167054   \n",
      "does_*__learned_*__learned_accept  0.733087  1.124671  0.608585  1.082789   \n",
      "try_*__try_will                    0.856234  1.193632  0.610529  1.184126   \n",
      "discuss_*__discuss_meets           0.868244  1.139364  0.624752  1.184790   \n",
      "consider_*__consider_will__if>*    0.919293  1.018082  0.624915  1.100036   \n",
      "consider_*__when>*                 1.019866  1.100504  0.633068  1.190985   \n",
      "consider_*__if>*                   0.900371  1.005391  0.635161  1.092304   \n",
      "\n",
      "                                   type_id  \n",
      "learned_*__will_*                      6.0  \n",
      "learned_*__will>*                      6.0  \n",
      "draw_*__will>*                         6.0  \n",
      "bear_*__bear_in__in>*                  6.0  \n",
      "draw_*__draw_will                      6.0  \n",
      "will_*                                 6.0  \n",
      "convey_*__convey_to                    6.0  \n",
      "convey_*__convey_to__convey_will       6.0  \n",
      "will>*__will_*                         6.0  \n",
      "does_*__learned_*__learned_accept      6.0  \n",
      "try_*__try_will                        6.0  \n",
      "discuss_*__discuss_meets               6.0  \n",
      "consider_*__consider_will__if>*        6.0  \n",
      "consider_*__when>*                     6.0  \n",
      "consider_*__if>*                       6.0  \n",
      "top response:\n",
      "                           0         1         2         3         4  \\\n",
      "note_says           0.989821  0.977690  0.957868  1.286824  0.812620   \n",
      "emphasise_*         1.027844  0.919210  0.845635  1.259257  0.834489   \n",
      "learned_*           0.983235  0.775386  0.935687  1.244620  0.671900   \n",
      "note_*              1.036282  0.975300  0.915639  1.349651  0.764689   \n",
      "be_important        1.067719  0.855092  0.865414  1.141331  0.834086   \n",
      "consider_is         0.953540  1.008597  0.810872  1.241812  0.843398   \n",
      "are_always          1.069939  1.023394  0.916837  1.268042  0.914358   \n",
      "is_consider         0.960232  0.971801  0.831468  1.144570  0.948569   \n",
      "consider_must       1.022316  0.965164  0.889595  1.283669  0.868974   \n",
      "convey_*            1.110495  1.076353  0.936242  1.273238  1.022821   \n",
      "be_possible         1.048697  0.795359  0.921976  1.205205  0.689573   \n",
      "take_must           0.987849  0.934348  0.930168  1.192227  0.829307   \n",
      "note_said           1.002821  0.894235  0.935777  1.311450  0.772550   \n",
      "be_say              0.985413  1.022340  0.946890  1.190916  0.863719   \n",
      "consider_certainly  1.006728  1.119145  0.811472  1.305048  0.936612   \n",
      "\n",
      "                           5         6         7  type_id  \n",
      "note_says           1.039128  0.603384  1.118851      6.0  \n",
      "emphasise_*         1.118552  0.608893  1.199739      6.0  \n",
      "learned_*           0.990506  0.618276  1.065652      6.0  \n",
      "note_*              1.089480  0.620788  1.070862      6.0  \n",
      "be_important        1.053088  0.631584  1.178807      6.0  \n",
      "consider_is         1.008453  0.639531  1.191159      6.0  \n",
      "are_always          1.145679  0.641656  1.160701      6.0  \n",
      "is_consider         1.022232  0.641745  1.229230      6.0  \n",
      "consider_must       1.119301  0.646483  1.185570      6.0  \n",
      "convey_*            1.152961  0.649417  1.196441      6.0  \n",
      "be_possible         0.963654  0.653824  1.068016      6.0  \n",
      "take_must           1.022142  0.668064  1.184106      6.0  \n",
      "note_said           1.137677  0.675306  1.107966      6.0  \n",
      "be_say              0.879330  0.677586  1.068506      6.0  \n",
      "consider_certainly  1.065111  0.684753  1.194288      6.0  \n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "top prompt:\n",
      "                                                     0         1         2  \\\n",
      "why>*                                         1.104096  1.277495  1.306421   \n",
      "explain_*                                     1.074950  1.264843  1.250738   \n",
      "admit_*                                       1.193359  1.260325  1.288746   \n",
      "admit_*__will>*                               1.222762  1.234878  1.309631   \n",
      "justify_*                                     1.194117  1.271824  1.319768   \n",
      "explain_*__explain_will                       1.080877  1.182869  1.291523   \n",
      "is>*__is_*__is_true                           1.162309  1.139200  1.311678   \n",
      "is_*__why>*                                   1.175892  1.168984  1.278892   \n",
      "does>*__realise_*__realise_does__realise_not  1.152017  1.244742  1.338369   \n",
      "admit_*__admit_will__will>*                   1.231131  1.266068  1.307017   \n",
      "explain_*__will>*                             1.092443  1.146115  1.287732   \n",
      "is_*__is_true                                 1.165552  1.179165  1.333115   \n",
      "admit_*__admit_will                           1.215929  1.298490  1.283715   \n",
      "how>*__how>does                               1.167098  1.238600  1.305153   \n",
      "is_*__is_why                                  1.197365  1.231318  1.274278   \n",
      "\n",
      "                                                     3         4         5  \\\n",
      "why>*                                         1.387563  0.890040  0.865998   \n",
      "explain_*                                     1.364432  0.897947  0.852793   \n",
      "admit_*                                       1.396757  0.925808  0.952902   \n",
      "admit_*__will>*                               1.359393  0.996535  1.007489   \n",
      "justify_*                                     1.358508  1.028394  0.993562   \n",
      "explain_*__explain_will                       1.372512  0.854090  0.924254   \n",
      "is>*__is_*__is_true                           1.481953  0.831132  1.024624   \n",
      "is_*__why>*                                   1.362826  0.828258  0.909416   \n",
      "does>*__realise_*__realise_does__realise_not  1.389140  0.905501  0.973377   \n",
      "admit_*__admit_will__will>*                   1.349086  1.047198  0.989124   \n",
      "explain_*__will>*                             1.335354  0.856301  0.917518   \n",
      "is_*__is_true                                 1.489960  0.884423  1.037931   \n",
      "admit_*__admit_will                           1.370550  1.019011  0.965366   \n",
      "how>*__how>does                               1.345073  0.981865  0.915864   \n",
      "is_*__is_why                                  1.422375  0.881879  0.949384   \n",
      "\n",
      "                                                     6         7  type_id  \n",
      "why>*                                         1.218400  0.576553      7.0  \n",
      "explain_*                                     1.200059  0.581301      7.0  \n",
      "admit_*                                       1.208874  0.586009      7.0  \n",
      "admit_*__will>*                               1.252459  0.596350      7.0  \n",
      "justify_*                                     1.244813  0.604280      7.0  \n",
      "explain_*__explain_will                       1.177795  0.606052      7.0  \n",
      "is>*__is_*__is_true                           1.101389  0.612163      7.0  \n",
      "is_*__why>*                                   1.209574  0.620568      7.0  \n",
      "does>*__realise_*__realise_does__realise_not  1.137492  0.624678      7.0  \n",
      "admit_*__admit_will__will>*                   1.283928  0.629214      7.0  \n",
      "explain_*__will>*                             1.133664  0.629701      7.0  \n",
      "is_*__is_true                                 1.156545  0.632958      7.0  \n",
      "admit_*__admit_will                           1.262404  0.633411      7.0  \n",
      "how>*__how>does                               1.225334  0.634334      7.0  \n",
      "is_*__is_why                                  1.230425  0.638297      7.0  \n",
      "top response:\n",
      "                     0         1         2         3         4         5  \\\n",
      "wonder_*      1.164943  1.106582  1.276903  1.314197  0.848936  0.880912   \n",
      "failed_*      1.204485  1.124149  1.325940  1.336414  0.916511  0.960918   \n",
      "were_*        1.199059  1.066386  1.362643  1.349828  0.904496  1.076865   \n",
      "is_wrong      1.162171  1.148290  1.384513  1.314271  0.934694  0.974407   \n",
      "instead>*     1.170362  1.231754  1.257461  1.263558  0.987653  0.854655   \n",
      "am_surprised  1.159865  1.219641  1.229011  1.333929  0.948790  1.030188   \n",
      "talks_*       1.231180  1.256361  1.227169  1.337933  1.019082  0.901977   \n",
      "talks_about   1.223082  1.293428  1.222819  1.339095  1.035168  0.889763   \n",
      "were_there    1.201340  1.148576  1.388233  1.355567  0.983789  1.096035   \n",
      "astonished_*  1.202651  1.196230  1.305231  1.333094  1.018210  1.151290   \n",
      "surely>*      1.139462  1.009522  1.179284  1.314364  0.728407  0.957278   \n",
      "suggest_to    1.139849  1.207259  1.228474  1.315161  0.945578  0.860964   \n",
      "hoped_*       1.089816  1.259839  1.293617  1.320115  0.966500  0.982924   \n",
      "was_for       1.193836  1.287366  1.424377  1.406558  1.131729  1.125883   \n",
      "suggest_*     1.146471  1.128591  1.096500  1.303793  0.783320  0.763265   \n",
      "\n",
      "                     6         7  type_id  \n",
      "wonder_*      1.180662  0.606207      7.0  \n",
      "failed_*      1.252548  0.654931      7.0  \n",
      "were_*        1.195550  0.672637      7.0  \n",
      "is_wrong      1.248959  0.681267      7.0  \n",
      "instead>*     1.205783  0.681974      7.0  \n",
      "am_surprised  1.206338  0.696276      7.0  \n",
      "talks_*       1.232762  0.699943      7.0  \n",
      "talks_about   1.235879  0.707574      7.0  \n",
      "were_there    1.244528  0.714718      7.0  \n",
      "astonished_*  1.234952  0.721673      7.0  \n",
      "surely>*      1.086058  0.721925      7.0  \n",
      "suggest_to    1.164441  0.729415      7.0  \n",
      "hoped_*       1.239720  0.729955      7.0  \n",
      "was_for       1.342660  0.732654      7.0  \n",
      "suggest_*     1.026639  0.737730      7.0  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i)\n",
    "    pt.display_type(i,  k=15)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming a single utterance. The model will annotate each utterance with a set of rerpesntations or features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt = pt.transform_utterance(utt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the phrasing motifs, i.e., a representation of how each sentence in the utterance is phrased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agree_* agree_*__does>* does>*',\n",
       " 'agree_* agree_*__agree_also agree_*__does>* does>*',\n",
       " 'as>* share_* share_*__share_does']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.get_info('motifs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector representation encapsulating the utterance's rhetorical intent (in short, an embedding of the utterance based on the responses associated with questions containing its constituent phrasings. see paper for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.17103395551495287,\n",
       " 0.030694092789899603,\n",
       " -0.14371185586935595,\n",
       " 0.10998245525877463,\n",
       " -0.31508472326375,\n",
       " -0.03187113204172867,\n",
       " -0.22291774431496747,\n",
       " -0.1278562931647348,\n",
       " 0.17717804384550123,\n",
       " 0.02097518862685271,\n",
       " -0.3543799065246014,\n",
       " -0.23905016478526944,\n",
       " -0.0635970446676691,\n",
       " -0.19447723846509896,\n",
       " -0.05206238289580816,\n",
       " -0.033106993095678466,\n",
       " -0.4151244327411294,\n",
       " -0.060491493289427684,\n",
       " -0.11375878457482796,\n",
       " -0.017597837784700098,\n",
       " -0.046578984088077695,\n",
       " -0.5431360277316315,\n",
       " 0.12980649779704173,\n",
       " -0.08504893017823376]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.get_info('prompt_types__prompt_repr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distances between that vector and the centroid of each inferred cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.130855626510634,\n",
       " 0.39130608715180415,\n",
       " 0.9490040025393338,\n",
       " 1.1140869968500255,\n",
       " 0.7542719064025534,\n",
       " 1.1279773340447152,\n",
       " 0.8453197995402353,\n",
       " 1.1400944717972439]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.get_info('prompt_types__prompt_dists.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particular type of question, and how close it is to the centroid of that particular cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.get_info('prompt_types__prompt_type.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39130608715180415"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.get_info('prompt_types__prompt_type_dist.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n",
      "10000/433787 utterances processed\n",
      "20000/433787 utterances processed\n",
      "30000/433787 utterances processed\n",
      "40000/433787 utterances processed\n",
      "50000/433787 utterances processed\n",
      "60000/433787 utterances processed\n",
      "70000/433787 utterances processed\n",
      "80000/433787 utterances processed\n",
      "90000/433787 utterances processed\n",
      "100000/433787 utterances processed\n",
      "110000/433787 utterances processed\n",
      "120000/433787 utterances processed\n",
      "130000/433787 utterances processed\n",
      "140000/433787 utterances processed\n",
      "150000/433787 utterances processed\n",
      "160000/433787 utterances processed\n",
      "170000/433787 utterances processed\n",
      "180000/433787 utterances processed\n",
      "190000/433787 utterances processed\n",
      "200000/433787 utterances processed\n",
      "210000/433787 utterances processed\n",
      "220000/433787 utterances processed\n",
      "230000/433787 utterances processed\n",
      "240000/433787 utterances processed\n",
      "250000/433787 utterances processed\n",
      "260000/433787 utterances processed\n",
      "270000/433787 utterances processed\n",
      "280000/433787 utterances processed\n",
      "290000/433787 utterances processed\n",
      "300000/433787 utterances processed\n",
      "310000/433787 utterances processed\n",
      "320000/433787 utterances processed\n",
      "330000/433787 utterances processed\n",
      "340000/433787 utterances processed\n",
      "350000/433787 utterances processed\n",
      "360000/433787 utterances processed\n",
      "370000/433787 utterances processed\n",
      "380000/433787 utterances processed\n",
      "390000/433787 utterances processed\n",
      "400000/433787 utterances processed\n",
      "410000/433787 utterances processed\n",
      "420000/433787 utterances processed\n",
      "430000/433787 utterances processed\n",
      "433787/433787 utterances processed\n"
     ]
    }
   ],
   "source": [
    "corpus = pt.transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt1 = corpus.get_utterance('1987-03-04a.857.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop_* stop_*__stop_will stop_*__stop_will__will>* stop_*__will>* will>*',\n",
       " 'admit_* admit_*__admit_will admit_*__admit_will__will>* admit_*__will>* will>*',\n",
       " 'does>* does>*__does>not does>*__understand_* understand_* understand_*__understand_does']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt1.get_info('motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will the Secretary of State stop giving us what is called in the pop record industry a remix of alibis , excuses and gimmicks ? Will he admit that the number of homes built to rent last year by local authorities was the lowest in 62 years , that the housing investment programme net of capital receipts was the lowest in real terms since HIPs were invented and that , even during the past three years the number of repair and improvement grants , which would bring some private homes back into use , have dropped by 100,000 ? Does not the right hon Gentleman understand that , if the private owner and the local authority are starved of resources , we are left with lengthy queues , homelessness and all the other scandals of poor housing that exist today ?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt1.get_info('prompt_types__prompt_type.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try out the model on arbitrary input. For instance, we see that the following question is also of type 1 -- that is, similar to other questions which voice agreement or support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_utt = pt.transform_utterance('Do you share my distaste for cockroaches?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do>* share_*']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_utt.get_info('motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_utt.get_info('prompt_types__prompt_type.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serializing the model. This dumps both the underlying `PhrasingMotifs` and `PromptTypes` models to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing itemset counts\n",
      "writing downlinks\n",
      "writing itemset to ids\n",
      "writing meta information\n",
      "dumping embedding model\n",
      "dumping training embeddings\n",
      "dumping type model 8\n"
     ]
    }
   ],
   "source": [
    "pt.dump_models(os.path.join(ROOT_DIR, 'full_pipe_models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire pipeline can later be loaded back from memory and used to transform new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pt = PromptTypeWrapper(output_field='prompt_types_new',\n",
    "                           min_support=100, svd__n_components=25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading itemset counts\n",
      "reading downlinks\n",
      "reading itemset to ids\n",
      "reading meta information\n",
      "loading embedding model\n",
      "loading training embeddings\n",
      "loading type model 8\n"
     ]
    }
   ],
   "source": [
    "new_pt.load_models(os.path.join(ROOT_DIR, 'full_pipe_models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm_model  pt_model\r\n"
     ]
    }
   ],
   "source": [
    "pt_model_dir = os.path.join(ROOT_DIR, 'full_pipe_models')\n",
    "!ls $pt_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_str_utt = new_pt.transform_utterance('Do you share my distaste for cockroaches?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do>* share_*']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_str_utt.get_info('motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_str_utt.get_info('prompt_types_new__prompt_type.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
